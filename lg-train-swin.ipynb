{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Library"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:25:01.795688Z","iopub.status.busy":"2022-01-15T10:25:01.794986Z","iopub.status.idle":"2022-01-15T10:25:13.001673Z","shell.execute_reply":"2022-01-15T10:25:13.000732Z","shell.execute_reply.started":"2022-01-15T10:25:01.795591Z"},"trusted":true},"outputs":[],"source":["! pip install wandb opencv-python-headless==4.1.2.30 albumentations torch-summary timm==0.5.4 einops joblib icecream  -qq -U"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:25:13.004437Z","iopub.status.busy":"2022-01-15T10:25:13.004166Z","iopub.status.idle":"2022-01-15T10:25:17.843442Z","shell.execute_reply":"2022-01-15T10:25:17.842685Z","shell.execute_reply.started":"2022-01-15T10:25:13.004400Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import f1_score\n","from glob import glob\n","import pathlib\n","from pathlib import Path\n","from torchsummary import summary\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from pprint import pprint\n","import urllib.request\n","import csv\n","import numpy as np\n","from einops import rearrange, reduce, repeat\n","from torch.cuda import amp\n","from tqdm import tqdm\n","import wandb\n","import time\n","import copy\n","from collections import defaultdict\n","from sklearn.metrics import mean_squared_error\n","import joblib\n","import gc\n","import os\n","from icecream import ic\n","from sklearn.model_selection import train_test_split\n","import gc\n","import cv2\n","import copy\n","import time\n","import random\n","from PIL import Image\n","\n","# For data manipulation\n","import numpy as np\n","import pandas as pd\n","\n","# Pytorch Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda import amp\n","\n","# Utils\n","import joblib\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","# Sklearn Imports\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, KFold\n","\n","import timm\n","\n","import json\n","\n","# Albumentations for augmentations\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# For colored terminal text\n","from colorama import Fore, Back, Style\n","c_ = Fore.CYAN\n","sr_ = Style.RESET_ALL\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# For descriptive error messages\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","\n","\n","from sklearn.metrics import f1_score"]},{"cell_type":"markdown","metadata":{},"source":["# ENV"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:25:17.845495Z","iopub.status.busy":"2022-01-15T10:25:17.845230Z","iopub.status.idle":"2022-01-15T10:25:17.893347Z","shell.execute_reply":"2022-01-15T10:25:17.892018Z","shell.execute_reply.started":"2022-01-15T10:25:17.845458Z"},"trusted":true},"outputs":[],"source":["\n","# ENV = 'COLAB'\n","ENV = 'KAGGLE'\n","# ENV = 'SYSTEM'\n","\n","# Option for Mixed Precision\n","# FP16 = True\n","FP16 = False\n","\n","\n","CONFIG = dict(\n","    seed=42,\n","    backbone='swin_base_patch4_window12_384',\n","    embedder= None,\n","    train_batch_size=8,\n","    valid_batch_size=16,\n","    img_size=384,\n","    num_epochs=20,\n","    early_stopping = True,\n","    early_stopping_step = 5,\n","    learning_rate=1e-5,\n","    scheduler='CosineAnnealingLR',\n","    min_lr=1e-6,\n","    T_max=100,\n","    num_classes = 25,\n","    weight_decay=1e-6,\n","    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n","    competition='lg',\n","    _wandb_kernel='deb'\n",")\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# SET SEED "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:25:17.896790Z","iopub.status.busy":"2022-01-15T10:25:17.896189Z","iopub.status.idle":"2022-01-15T10:25:17.909599Z","shell.execute_reply":"2022-01-15T10:25:17.908786Z","shell.execute_reply.started":"2022-01-15T10:25:17.896748Z"},"trusted":true},"outputs":[],"source":["def set_seed(seed=42):\n","    '''Sets the seed of the entire notebook so results are the same every time we run.\n","    This is for REPRODUCIBILITY.'''\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","\n","\n","set_seed(CONFIG['seed'])\n"]},{"cell_type":"markdown","metadata":{},"source":["# Read the Data\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:25:17.911360Z","iopub.status.busy":"2022-01-15T10:25:17.910859Z","iopub.status.idle":"2022-01-15T10:28:30.802857Z","shell.execute_reply":"2022-01-15T10:28:30.801968Z","shell.execute_reply.started":"2022-01-15T10:25:17.911319Z"},"trusted":true},"outputs":[],"source":["import wandb\n","run = wandb.init(project=\"lg\", entity=\"jiwon7258\",\n","                 config=CONFIG, job_type='train')\n","dataset = wandb.run.use_artifact(\n","    'jiwon7258/lg/lg_train:v0', type='dataset')\n","\n","\n","# Download the artifact's contents\n","dataset_dir = dataset.download()\n","dataset_dir = Path(dataset_dir)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:28:30.804754Z","iopub.status.busy":"2022-01-15T10:28:30.804383Z","iopub.status.idle":"2022-01-15T10:28:30.809944Z","shell.execute_reply":"2022-01-15T10:28:30.809259Z","shell.execute_reply.started":"2022-01-15T10:28:30.804698Z"},"trusted":true},"outputs":[],"source":["TRAIN_PATH = dataset_dir\n","# TEST_PATH = dataset_dir / 'test'"]},{"cell_type":"markdown","metadata":{},"source":["# Augmentations"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:28:30.813928Z","iopub.status.busy":"2022-01-15T10:28:30.811190Z","iopub.status.idle":"2022-01-15T10:28:30.822155Z","shell.execute_reply":"2022-01-15T10:28:30.821435Z","shell.execute_reply.started":"2022-01-15T10:28:30.813872Z"},"trusted":true},"outputs":[],"source":["data_transforms = {\n","    \"train\": A.Compose([\n","        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n","        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05,\n","                           rotate_limit=15, p=0.5),\n","        A.RGBShift(r_shift_limit=15, g_shift_limit=15,\n","                   b_shift_limit=15, p=0.5),\n","        A.RandomBrightnessContrast(p=0.5),\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p-0.5),\n","        A.Normalize(),\n","        ToTensorV2()], p=1.),\n","\n","    \"valid\": A.Compose([\n","        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n","        A.Normalize(),\n","        ToTensorV2()], p=1.)\n","}\n"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:28:30.825534Z","iopub.status.busy":"2022-01-15T10:28:30.824486Z","iopub.status.idle":"2022-01-15T10:28:31.525603Z","shell.execute_reply":"2022-01-15T10:28:31.524866Z","shell.execute_reply.started":"2022-01-15T10:28:30.825498Z"},"trusted":true},"outputs":[],"source":["train_csv = sorted(glob(str(TRAIN_PATH / '*/*.csv')))\n","train_jpg = sorted(glob(str(TRAIN_PATH / '*/*.jpg')))\n","train_json = sorted(glob(str(TRAIN_PATH / '*/*.json')))\n","\n","\n","crops = []\n","diseases = []\n","risks = []\n","labels = []\n","\n","for i in range(len(train_json)):\n","    with open(train_json[i], 'r') as f:\n","        sample = json.load(f)\n","        crop = sample['annotations']['crop']\n","        disease = sample['annotations']['disease']\n","        risk = sample['annotations']['risk']\n","        label=f\"{crop}_{disease}_{risk}\"\n","    \n","        crops.append(crop)\n","        diseases.append(disease)\n","        risks.append(risk)\n","        labels.append(label)\n","        \n","label_unique = sorted(np.unique(labels))\n","label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n","\n","train_labels = [label_unique[k] for k in labels] # len = train_len"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import joblib\n","joblib.dump(label_unique, 'label_unique')\n","wandb.save('label_unique')"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:28:31.539757Z","iopub.status.busy":"2022-01-15T10:28:31.539171Z","iopub.status.idle":"2022-01-15T10:28:31.561040Z","shell.execute_reply":"2022-01-15T10:28:31.560138Z","shell.execute_reply.started":"2022-01-15T10:28:31.539702Z"},"trusted":true},"outputs":[],"source":["X_train, X_val, y_train, y_val = train_test_split(train_jpg, train_labels, test_size=0.1, stratify = train_labels)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:28:31.562715Z","iopub.status.busy":"2022-01-15T10:28:31.562438Z","iopub.status.idle":"2022-01-15T10:28:31.587681Z","shell.execute_reply":"2022-01-15T10:28:31.586382Z","shell.execute_reply.started":"2022-01-15T10:28:31.562681Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, train_img, train_label, transforms=None):\n","        self.imgs = train_img\n","        self.labels = train_label\n","        self.transforms = transforms\n","        \n","    def __len__(self):\n","        return len(self.imgs)\n","    \n","    def __getitem__(self, index):\n","        img_path = self.imgs[index]\n","        img = cv2.imread(img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        target = self.labels[index]\n","        \n","        if self.transforms:\n","            img = self.transforms(image=img)[\"image\"]\n","            \n","        return img, target\n","    \n","trainDataset = CustomDataset(X_train, y_train, transforms = data_transforms['train'])\n","trainDataloader = DataLoader(\n","    trainDataset, batch_size=CONFIG['train_batch_size'], shuffle=True)\n","\n","validDataset = CustomDataset(X_val, y_val, transforms = data_transforms['valid'])\n","validDataloader = DataLoader(validDataset, batch_size = CONFIG['valid_batch_size'], shuffle = True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:28:31.595710Z","iopub.status.busy":"2022-01-15T10:28:31.592703Z","iopub.status.idle":"2022-01-15T10:29:04.375344Z","shell.execute_reply":"2022-01-15T10:29:04.374595Z","shell.execute_reply.started":"2022-01-15T10:28:31.595662Z"},"trusted":true},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, backbone, embedder, pretrained=True):\n","        super(Model, self).__init__()\n","        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n","        self.n_features = self.backbone.head.in_features\n","        self.backbone.reset_classifier(0)\n","        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n","\n","    def forward(self, images):\n","        # features = (bs, embedding_size)\n","        features = self.backbone(images)\n","        # outputs  = (bs, num_classes)\n","        output = self.fc(features)\n","        return output\n","\n","\n","model = Model(CONFIG['backbone'], CONFIG['embedder'], pretrained = True)\n","model.to(CONFIG['device'])\n",";"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:29:04.376696Z","iopub.status.busy":"2022-01-15T10:29:04.376445Z","iopub.status.idle":"2022-01-15T10:29:04.383964Z","shell.execute_reply":"2022-01-15T10:29:04.383287Z","shell.execute_reply.started":"2022-01-15T10:29:04.376660Z"},"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(\n","    params=model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:29:04.385682Z","iopub.status.busy":"2022-01-15T10:29:04.385257Z","iopub.status.idle":"2022-01-15T10:29:05.537793Z","shell.execute_reply":"2022-01-15T10:29:05.536741Z","shell.execute_reply.started":"2022-01-15T10:29:04.385649Z"},"trusted":true},"outputs":[],"source":["def criterion(logits: torch.tensor, targets: torch.tensor):\n","    return nn.CrossEntropyLoss()(logits.view(-1,CONFIG['num_classes']), targets.view(-1))"]},{"cell_type":"markdown","metadata":{},"source":["   # Training Function"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:33:47.356814Z","iopub.status.busy":"2022-01-15T10:33:47.356540Z","iopub.status.idle":"2022-01-15T10:33:47.375626Z","shell.execute_reply":"2022-01-15T10:33:47.373734Z","shell.execute_reply.started":"2022-01-15T10:33:47.356781Z"},"trusted":true},"outputs":[],"source":["def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    # train 모드로 변경\n","    model.train()\n","\n","    # for the Mixed Precision\n","    # Pytorch 예제 : https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples\n","    if(FP16):\n","        scaler = amp.GradScaler()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","    step_acc = 0\n","    accuracy = 0\n","    f1 = 0\n","\n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","\n","    for step, (img, target) in bar:\n","        img = img.to(device)\n","        target = target.to(device)\n","\n","        batch_size = img.shape[0]\n","\n","        if(FP16):\n","            with amp.autocast(enabled=True):\n","                logits = model(img)\n","                loss = criterion(logits, target)\n","\n","                # loss를 Scale\n","                # Scaled Grdients를 계산(call)하기 위해 scaled loss를 backward()\n","                scaler.scale(loss).backward()\n","                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n","                # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n","                # otherwise, optimizer.step() is skipped.\n","                scaler.step(optimizer)\n","\n","                # Updates the scale for next iteration.\n","                scaler.update()\n","\n","        else:\n","            logits = model(img)\n","            loss = criterion(logits, target)\n","\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n","            optimizer.step()\n","\n","        # logits (bs, seq_len, VOCAB_SIZE)\n","        # trg_output (bs, seq_len)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # change learning rate by Scheduler\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        # loss.item()은 loss를 Python Float으로 반환\n","        # loss.item()은 batch data의 average loss이므로, sum of loss를 구하기 위해 batch_size를 곱해준다\n","        running_loss += loss.item() * batch_size\n","        dataset_size += batch_size\n","        \n","        # logits\n","        logits = logits.detach().cpu()\n","\n","        # acc, f1\n","        output = np.argmax(torch.softmax(logits, dim = -1), axis = -1)\n","        step_acc = np.mean(\n","            output.view(-1).numpy() == target.view(-1).detach().cpu().numpy())\n","        step_f1 = f1_score(output.view(-1).numpy(),\n","                           target.view(-1).detach().cpu().numpy(),average='macro')\n","        accuracy += step_acc\n","        f1 += step_f1\n","\n","        # loss\n","        train_loss = running_loss / dataset_size\n","\n","        bar.set_postfix(\n","            Epoch=epoch, Train_Loss=train_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy=accuracy / np.float(\n","                step+1), f1 = f1 / np.float(step+1)\n","        )\n","\n","        # break\n","\n","    accuracy /= len(dataloader)\n","    f1 /= len(dataloader)\n","    # Garbage Collector\n","    gc.collect()\n","\n","    return train_loss, accuracy, f1\n"]},{"cell_type":"markdown","metadata":{},"source":["   # Validation Function"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:33:47.378229Z","iopub.status.busy":"2022-01-15T10:33:47.377682Z","iopub.status.idle":"2022-01-15T10:33:47.393570Z","shell.execute_reply":"2022-01-15T10:33:47.392783Z","shell.execute_reply.started":"2022-01-15T10:33:47.378191Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","    accuracy = 0\n","    f1 = 0\n","\n","\n","    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n","\n","    for step, (img, target) in bar:\n","        img = img.to(device)\n","        target = target.to(device)\n","\n","        batch_size = img.shape[0]\n","\n","        logits = model(img)\n","        loss = criterion(logits, target)\n","\n","        running_loss += loss.item() * batch_size\n","        dataset_size += batch_size\n","\n","        # 실시간으로 정보를 표시하기 위한 epoch loss\n","        val_loss = running_loss / dataset_size\n","\n","        # logits\n","        logits = logits.detach().cpu()\n","        \n","        output = np.argmax(torch.softmax(logits, dim=-1), axis=-1)\n","        step_acc = np.mean(\n","            output.view(-1).numpy() == target.view(-1).detach().cpu().numpy())\n","        step_f1 = f1_score(output.view(-1).numpy(),\n","                           target.view(-1).detach().cpu().numpy(), average='macro')\n","        accuracy += step_acc\n","        f1 += step_f1\n","\n","\n","        bar.set_postfix(\n","            Epoch=epoch, Valid_Loss=val_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy=accuracy / np.float(\n","                step+1), f1 = f1 / np.float(step+1)\n","        )\n","\n","        # break\n","\n","    accuracy /= len(dataloader)\n","    f1 /= len(dataloader)\n","\n","    gc.collect()\n","\n","    return val_loss, accuracy, f1\n"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:33:47.395930Z","iopub.status.busy":"2022-01-15T10:33:47.395337Z","iopub.status.idle":"2022-01-15T10:33:47.415192Z","shell.execute_reply":"2022-01-15T10:33:47.414280Z","shell.execute_reply.started":"2022-01-15T10:33:47.395894Z"},"trusted":true},"outputs":[],"source":["def run_training(\n","    model,\n","    optimizer,\n","    scheduler,\n","    device,\n","    num_epochs,\n","    metric_prefix=\"\",\n","    file_prefix=\"\",\n","    early_stopping=True,\n","    early_stopping_step=10,\n","):\n","    # To automatically log graidents\n","    wandb.watch(model, log_freq=100)\n","\n","    if torch.cuda.is_available():\n","        print(\"[INFO] Using GPU:{}\\n\".format(torch.cuda.get_device_name()))\n","\n","    start = time.time()\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_loss = np.inf\n","    history = defaultdict(list)\n","    early_stop_counter = 0\n","\n","    # num_epochs만큼, train과 val을 실행한다\n","    for epoch in range(1, num_epochs + 1):\n","        gc.collect()\n","\n","        train_train_loss, train_accuracy, train_f1 = train_one_epoch(\n","            model,\n","            optimizer,\n","            scheduler,\n","            dataloader=trainDataloader,\n","            device=device,\n","            epoch=epoch,\n","        )\n","\n","        val_loss, val_accuracy, val_f1 = valid_one_epoch(\n","            model, validDataloader, device=device, epoch=epoch\n","        )\n","\n","        history[f\"{metric_prefix}Train Loss\"].append(train_train_loss)\n","        history[f\"{metric_prefix}Train Accuracy\"].append(train_accuracy)\n","        history[f\"{metric_prefix}Train F1\"].append(train_f1)\n","        history[f\"{metric_prefix}Valid Loss\"].append(val_loss)\n","        history[f\"{metric_prefix}Valid Accuracy\"].append(val_accuracy)\n","        history[f\"{metric_prefix}Valid F1\"].append(val_f1)\n","\n","\n","        # Log the metrics\n","        wandb.log(\n","            {\n","                f\"{metric_prefix}Train Loss\": train_train_loss,\n","                f\"{metric_prefix}Valid Loss\": val_loss,\n","                f\"{metric_prefix}Train Accuracy\": train_accuracy,\n","                f\"{metric_prefix}Valid Accuracy\": val_accuracy,\n","                f\"{metric_prefix}Train F1\" : train_f1,\n","                f\"{metric_prefix}Valid F1\" : val_f1,\n","            }\n","        )\n","\n","        print(f\"Valid Loss : {val_loss}\")\n","\n","        # deep copy the model\n","        if val_loss <= best_loss:\n","            early_stop_counter = 0\n","\n","            print(\n","                f\"Validation Loss improved( {best_loss} ---> {val_loss}  )\"\n","            )\n","\n","            # Update Best Loss\n","            best_loss = val_loss\n","\n","            # Update Best Model Weight\n","            # run.summary['Best RMSE'] = best_loss\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","\n","            PATH = \"{}epoch{:.0f}_Loss{:.4f}.bin\".format(\n","                file_prefix, epoch, best_loss)\n","            torch.save(model.state_dict(), PATH)\n","            torch.save(model.state_dict(),\n","                       f\"{file_prefix}best_{epoch}epoch.bin\")\n","            # Save a model file from the current directory\n","            wandb.save(PATH)\n","\n","            print(f\"Model Saved\")\n","\n","        elif early_stopping:\n","            early_stop_counter += 1\n","            if early_stop_counter > early_stopping_step:\n","                break\n","\n","        # break\n","\n","    end = time.time()\n","    time_elapsed = end - start\n","    print(\n","        \"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n","            time_elapsed // 3600,\n","            (time_elapsed % 3600) // 60,\n","            (time_elapsed % 3600) % 60,\n","        )\n","    )\n","    print(\"Best Loss: {:.4f}\".format(best_loss))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, history\n"]},{"cell_type":"markdown","metadata":{},"source":[" # Run training"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:33:47.416354Z","iopub.status.busy":"2022-01-15T10:33:47.416056Z","iopub.status.idle":"2022-01-15T10:33:48.692352Z","shell.execute_reply":"2022-01-15T10:33:48.691550Z","shell.execute_reply.started":"2022-01-15T10:33:47.416328Z"},"trusted":true},"outputs":[],"source":["wandb.restore('epoch3_Loss0.1026.bin', 'jiwon7258/lg/2mzc3731', root='./')\n","model.load_state_dict(torch.load('epoch3_Loss0.1026.bin',\n","                      map_location=CONFIG['device']))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-15T10:33:48.694521Z","iopub.status.busy":"2022-01-15T10:33:48.694198Z"},"trusted":true},"outputs":[],"source":["run_training(\n","    model=model,\n","    optimizer=optimizer,\n","    scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(\n","        optimizer=optimizer, T_max=CONFIG['T_max'], eta_min=CONFIG['min_lr']),\n","    device=device,\n","    num_epochs=CONFIG['num_epochs'],\n","    metric_prefix=\"\",\n","    file_prefix=\"\",\n","    early_stopping=CONFIG['early_stopping'],\n","    early_stopping_step=CONFIG['early_stopping_step'],\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), 'final.bin')\n","wandb.save('final.bin')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
