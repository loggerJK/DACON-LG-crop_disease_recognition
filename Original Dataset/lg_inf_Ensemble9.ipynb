{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15541,"status":"ok","timestamp":1642767169807,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"rta_-XDLrKRm","outputId":"20e65e03-666d-431b-dac6-f065dcff0922"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.7 MB 12.2 MB/s \n","\u001b[K     |████████████████████████████████| 21.8 MB 1.6 MB/s \n","\u001b[K     |████████████████████████████████| 102 kB 39.0 MB/s \n","\u001b[K     |████████████████████████████████| 431 kB 43.8 MB/s \n","\u001b[K     |████████████████████████████████| 97 kB 5.5 MB/s \n","\u001b[K     |████████████████████████████████| 142 kB 47.5 MB/s \n","\u001b[K     |████████████████████████████████| 180 kB 45.4 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n","\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["! pip install wandb opencv-python-headless==4.1.2.30 albumentations torch-summary timm==0.5.4 einops joblib icecream  -qq -U"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCC9pGxmrKRr"},"outputs":[],"source":["import warnings\n","from glob import glob\n","import pathlib\n","from pathlib import Path\n","from torchsummary import summary\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from pprint import pprint\n","import urllib.request\n","import csv\n","import numpy as np\n","from einops import rearrange, reduce, repeat\n","from torch.cuda import amp\n","from tqdm import tqdm\n","import wandb\n","import time\n","import copy\n","from collections import defaultdict\n","from sklearn.metrics import mean_squared_error\n","import joblib\n","import gc\n","import os\n","from icecream import ic\n","from sklearn.model_selection import train_test_split\n","import gc\n","import cv2\n","import copy\n","import time\n","import random\n","from PIL import Image\n","\n","# For data manipulation\n","import numpy as np\n","import pandas as pd\n","from einops import rearrange, repeat\n","from scipy import stats\n","\n","# Pytorch Imports\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda import amp\n","\n","# Utils\n","import joblib\n","from tqdm import tqdm\n","from collections import defaultdict\n","import matplotlib.pyplot as plt\n","\n","# Sklearn Imports\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, KFold\n","\n","import timm\n","\n","import json\n","\n","# Albumentations for augmentations\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","# For colored terminal text\n","from colorama import Fore, Back, Style\n","c_ = Fore.CYAN\n","sr_ = Style.RESET_ALL\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# For descriptive error messages\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"]},{"cell_type":"markdown","metadata":{"id":"ysa5y6bZMuyq"},"source":["# ENV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_XeMSpQNrKRt"},"outputs":[],"source":["# Option for Mixed Precision\n","# FP16 = True\n","FP16 = False\n","\n","\n","CONFIG = dict(\n","    nickname = 'Ensemble 9',\n","    seed=42,\n","    backbone=None,\n","    embedder=None,\n","    train_batch_size=8,\n","    valid_batch_size=16,\n","    img_size=384,\n","    num_epochs=5,\n","    early_stopping=False,\n","    early_stopping_step=10,\n","    learning_rate=1e-4,\n","    scheduler='CosineAnnealingLR',\n","    min_lr=1e-6,\n","    T_max=100,\n","    num_classes=25,\n","    weight_decay=1e-6,\n","    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n","    competition='lg',\n","    _wandb_kernel='deb'\n",")\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dcP2gaN8rKRu"},"outputs":[],"source":["def set_seed(seed=42):\n","    '''Sets the seed of the entire notebook so results are the same every time we run.\n","    This is for REPRODUCIBILITY.'''\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    # Set a fixed value for the hash seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","\n","\n","set_seed(CONFIG['seed'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"elapsed":1008785,"status":"ok","timestamp":1642768255705,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"KZMUcAF9rKRu","outputId":"977360b0-5735-4ba5-a107-0661142858de"},"outputs":[{"data":{"application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"name":"stdout","output_type":"stream","text":["wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/jiwon7258/lg/runs/3cvv61iw\" target=\"_blank\">dashing-violet-88</a></strong> to <a href=\"https://wandb.ai/jiwon7258/lg\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact lg:v1, 9188.81MB. 121115 files... Done. 0:0:0\n"]}],"source":["import wandb\n","\n","\n","run = wandb.init(project=\"lg\",\n","                 entity=\"jiwon7258\",\n","                 config=CONFIG,\n","                 job_type='inf',\n","                #  id='1l0lpdqx',\n","                #  resume='must'\n",")\n","\n","\n","dataset = wandb.run.use_artifact(\n","    'jiwon7258/lg/lg:v1', type='dataset')\n","\n","run.name = CONFIG['nickname']\n","\n","# Download the artifact's contents\n","dataset_dir = dataset.download()\n","dataset_dir = Path(dataset_dir)\n"]},{"cell_type":"markdown","metadata":{"id":"4rF6wAN4rKRv"},"source":["# Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oYgDFfbOrKRx"},"outputs":[],"source":["data_transforms = {\n","    \"train\": A.Compose([\n","        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n","        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05,\n","                           rotate_limit=15, p=0.5),\n","        A.RGBShift(r_shift_limit=15, g_shift_limit=15,\n","                   b_shift_limit=15, p=0.5),\n","        A.RandomBrightnessContrast(p=0.5),\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","        A.Normalize(),\n","        ToTensorV2(),\n","        ], p=1.),\n","}\n","data_transforms_valid = {\n","    224: A.Compose([\n","        A.Resize(224, 224),\n","        A.Normalize(),\n","        ToTensorV2()], p=1.),\n","\n","\n","    384: A.Compose([\n","        A.Resize(384, 384),\n","        A.Normalize(),\n","        ToTensorV2()], p=1.),\n","\n","\n","    # 512: A.Compose([\n","    #     A.Resize(512, 512),\n","    #     A.Normalize(),\n","    #     ToTensorV2()], p=1.)\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"SmOlqkaWrKRz"},"source":["# Dataset Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9-4OTy8rKR0"},"outputs":[],"source":["# dataset_dir = Path('./')\n","TEST_PATH =  dataset_dir / 'test'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-rfoE1VrKR1"},"outputs":[],"source":["test_csv = sorted(glob(str(TEST_PATH / '*/*.csv')))\n","test_jpg = sorted(glob(str(TEST_PATH / '*/*.jpg')))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8YsRdyfvrKR1"},"outputs":[],"source":["# # TTA\n","# class TestDataset(Dataset):\n","#     def __init__ (self, N, test_imgs, transforms = None):\n","#         self.N = N\n","#         self.test_imgs = test_imgs\n","#         self.transforms = transforms\n","\n","\n","#     def __len__ (self):\n","#         return len(self.test_imgs)\n","\n","#     def __getitem__(self, index):\n","#         img_path = self.test_imgs[index]\n","#         img_code = (Path(img_path)).parent.stem\n","#         img = cv2.imread(img_path)\n","#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        \n","#         imgs = [self.transforms(image=img)['image'] for _ in range(self.N)]\n","#         imgs = np.concatenate(imgs, axis = 0)\n","#         imgs = rearrange(imgs, '(new1 bs) h w -> new1 bs h w', new1=self.N)\n","\n","#         return imgs, img_code\n","\n","# testDataset = TestDataset(8, test_jpg, transforms = data_transforms['train'])\n","# testDataloader = DataLoader(\n","#     testDataset, batch_size=CONFIG['valid_batch_size'], shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GZdAhiO3rKR2"},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, test_imgs, transforms=None):\n","        self.test_imgs = test_imgs\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.test_imgs)\n","\n","    def __getitem__(self, index):\n","        img_path = self.test_imgs[index]\n","        img_code = (Path(img_path)).parent.stem\n","        img = cv2.imread(img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","        img_list = [transform(image=img)['image'] for transform in self.transforms.values()]\n","        \n","\n","        return img_list, img_code\n","\n","# 384\n","testDataset = TestDataset(test_jpg, transforms=data_transforms_valid)\n","testDataloader = DataLoader(\n","    testDataset, batch_size=CONFIG['valid_batch_size'], shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yzyKYsi7rKR2"},"outputs":[],"source":["# for imgs, img_code in testDataset :\n","#     fig, axes = plt.subplots(1,8, figsize = (40,20))\n","#     for i in range(8):\n","#         img = imgs[i, :, :, :]\n","#         axes[i].imshow(img.reshape(384,384,3))\n","#     break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6tj6gB23rKR3","outputId":"98a7541d-774e-4f56-efa9-bf0d6c1563f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 224, 224])\n","torch.Size([16, 3, 384, 384])\n","torch.Size([16, 3, 512, 512])\n","<class 'tuple'>\n"]}],"source":["for img_list, img_code in testDataloader:\n","    for i in range(len(img_list)):\n","        print(img_list[i].shape)\n","    print(type(img_code))\n","    break\n"]},{"cell_type":"markdown","metadata":{"id":"OkE-L-9BrKR3"},"source":["# Key Value Dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tMbZPaF5rKR4"},"outputs":[],"source":["wandb.restore('class_dict', run_path='jiwon7258/lg/1lkvc6n0', root='./')\n","class_dict = joblib.load('class_dict')"]},{"cell_type":"markdown","metadata":{"id":"vgPxm-evrKR4"},"source":["# MODELS"]},{"cell_type":"markdown","metadata":{"id":"3vIqZ-eprKR4"},"source":["## EfficientNet V2 M"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":2570,"status":"ok","timestamp":1642768408839,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"bcdXMKymrKR5","outputId":"b688a264-0d89-468d-cf64-ab25902aa3e3"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["''"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["class Effnet(nn.Module):\n","    def __init__(self, backbone, embedder, pretrained=True):\n","        super().__init__()\n","        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n","        self.backbone.reset_classifier(0)\n","        self.n_features = 1280\n","        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n","\n","    def forward(self, images):\n","        # features = (bs, embedding_size)\n","        features = self.backbone(images)\n","        # outputs  = (bs, num_classes)\n","        output = self.fc(features)\n","        return output\n","\n","\n","effnet = Effnet('tf_efficientnetv2_m',None, pretrained=False)\n","effent = effnet.to(CONFIG['device'])\n",";"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2229,"status":"ok","timestamp":1642768411063,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"KcgQHp76rKR5","outputId":"eca4845a-c3a6-48f3-bc4a-58e0279679ab"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["wandb.restore('tf_efficientnetv2_m finecutmixlast.bin',\n","              'jiwon7258/lg/lwda8bn3', root='./')\n","effnet.load_state_dict(torch.load('tf_efficientnetv2_m finecutmixlast.bin',\n","                      map_location=CONFIG['device']))\n"]},{"cell_type":"markdown","metadata":{"id":"nsOQWdHqrKR5"},"source":["## Swin B "]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":4579,"status":"ok","timestamp":1642768661416,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"r4glrKmmrKR5","outputId":"75217b5b-68f3-48c1-808d-43d899c5f056"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["''"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["class Swin(nn.Module):\n","    def __init__(self, backbone, embedder, pretrained=True):\n","        super(Swin, self).__init__()\n","        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n","        self.n_features = self.backbone.head.in_features\n","        self.backbone.reset_classifier(0)\n","        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n","\n","    def forward(self, images):\n","        # features = (bs, embedding_size)\n","        features = self.backbone(images)\n","        # outputs  = (bs, num_classes)\n","        output = self.fc(features)\n","        return output\n","\n","\n","swin = Swin('swin_base_patch4_window12_384',\n","            None, pretrained=False)\n","swin.to(CONFIG['device'])\n",";"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15644,"status":"ok","timestamp":1642768700350,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"RWtGjfeCrKR6","outputId":"760b75ac-9fe4-4fb3-f47d-e0704a51fd44"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["wandb.restore('epoch125_Loss0.0002.bin', 'jiwon7258/lg/1ycjalgj', root='./')\n","swin.load_state_dict(torch.load('epoch125_Loss0.0002.bin',\n","                      map_location=CONFIG['device']))\n"]},{"cell_type":"markdown","metadata":{"id":"VdxMNIHErKR6"},"source":["## DeiT"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":3966,"status":"ok","timestamp":1642768704311,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"ksIqg6-BrKR6","outputId":"bc9deca6-77cb-418e-aec8-7ca2e0bc1aa9"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["''"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["class Deit(nn.Module):\n","    def __init__(self, backbone, embedder, pretrained=True):\n","        super(Deit, self).__init__()\n","        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n","        self.backbone.reset_classifier(0)\n","        self.n_features = 768\n","        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n","\n","    def forward(self, images):\n","        # features = (bs, embedding_size)\n","        features = self.backbone(images)\n","        # outputs  = (bs, num_classes)\n","        if isinstance(features, tuple):\n","          features = features[0]\n","        output = self.fc(features)\n","        return output\n","\n","\n","deit = Deit('deit_base_distilled_patch16_384',\n","            None, pretrained=False)\n","deit.to(CONFIG['device'])\n",";"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13816,"status":"ok","timestamp":1642768718114,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"HdkIJzBIrKR7","outputId":"c7de9a04-af97-4d64-c96a-b3951e1fb9e7"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["wandb.restore('deit finecutmixlast.bin', 'jiwon7258/lg/5ikpl9uv', root='./')\n","deit.load_state_dict(torch.load(\n","    'deit finecutmixlast.bin', map_location=CONFIG['device']))\n"]},{"cell_type":"markdown","metadata":{"id":"WSaGNEnbrKR7"},"source":["## EfficientNet B4 NS 512"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":2045,"status":"ok","timestamp":1642768720144,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"G9yr5bz3rKR7","outputId":"47bb443c-9958-4199-d5dd-977077766571"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["''"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["class Noisy(nn.Module):\n","    def __init__(self, backbone, embedder, pretrained=True):\n","        super(Noisy, self).__init__()\n","        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n","        self.backbone.reset_classifier(0)\n","        self.n_features = 1792\n","        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n","\n","    def forward(self, images):\n","        # features = (bs, embedding_size)\n","        features = self.backbone(images)\n","        # outputs  = (bs, num_classes)\n","        # if isinstance(features, tuple):\n","        #   features = features[0]\n","        output = self.fc(features)\n","        return output\n","\n","\n","b4ns512 = Noisy('tf_efficientnet_b4_ns', None, pretrained=False)\n","b4ns512.to(CONFIG['device'])\n",";"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6307,"status":"ok","timestamp":1642768726446,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"SJs8BxrtrKR7","outputId":"98e181bf-1b17-4095-a42c-08e068e81202"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["wandb.restore('epoch71_Loss0.0003.bin', 'jiwon7258/lg/1v3ffaqb', root='./')\n","b4ns512.load_state_dict(torch.load(\n","    'epoch71_Loss0.0003.bin', map_location=CONFIG['device']))\n"]},{"cell_type":"markdown","metadata":{"id":"pZpfOOYDMuzI"},"source":["## CoAtNet Mini 224"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":1870,"status":"ok","timestamp":1642768728293,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"2jBgOrefMuzR","outputId":"b53466f3-d0f2-4b8f-e956-965166aa2c46"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["''"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["class Coat(nn.Module):\n","    def __init__(self, backbone, embedder, pretrained=True):\n","        super(Coat, self).__init__()\n","        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n","        self.backbone.reset_classifier(0)\n","        self.n_features = self.backbone.num_features\n","        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n","\n","    def forward(self, images):\n","        # features = (bs, embedding_size)\n","        features = self.backbone(images)\n","        # outputs  = (bs, num_classes)\n","        # if isinstance(features, tuple):\n","        #   features = features[0]\n","        output = self.fc(features)\n","        return output\n","\n","\n","coatmini224 = Coat('coat_mini', None, pretrained=False)\n","coatmini224.to(CONFIG['device'])\n",";"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4089,"status":"ok","timestamp":1642768732378,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"ZHlamfeSMuzS","outputId":"f4e32a30-a31a-411a-98a4-f80b3eee8277"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["wandb.restore('CoAtNet mini finecutmixlast.bin',\n","              'jiwon7258/lg/zwfbinnt', root='./')\n","coatmini224.load_state_dict(torch.load(\n","    'CoAtNet mini finecutmixlast.bin', map_location=CONFIG['device']))\n"]},{"cell_type":"markdown","metadata":{"id":"3O6euLuJMuzS"},"source":["## BEiT 224 in 22k"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4490,"status":"ok","timestamp":1642768736853,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"_U5IdomCMuzS","outputId":"dd0f0885-f215-4bfb-c526-895b1caefdf6"},"outputs":[],"source":["class Beit(nn.Module):\n","    def __init__(self, backbone, embedder, pretrained=True):\n","        super(Beit, self).__init__()\n","        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n","        self.backbone.reset_classifier(0)\n","        self.n_features = self.backbone.num_features\n","        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n","\n","    def forward(self, images):\n","        # features = (bs, embedding_size)\n","        features = self.backbone(images)\n","        # outputs  = (bs, num_classes)\n","        # if isinstance(features, tuple):\n","        #   features = features[0]\n","        output = self.fc(features)\n","        return output\n","\n","\n","beit224 = Beit('beit_base_patch16_224_in22k',\n","            None,\n","             pretrained=False)\n","beit224.to(CONFIG['device']);"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12819,"status":"ok","timestamp":1642768749649,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"tmjO69rTMuzT","outputId":"efe18223-f459-4d24-dfa0-db8ff20afe2f"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["wandb.restore('BEiT 224 in22k finecutmixlast.bin',\n","              'jiwon7258/lg/288jowyh', root='./')\n","beit224.load_state_dict(torch.load(\n","    'BEiT 224 in22k finecutmixlast.bin', map_location=CONFIG['device']))\n"]},{"cell_type":"markdown","metadata":{"id":"yOreA5NBMuzU"},"source":["## CaiT S24 224"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2942,"status":"ok","timestamp":1642768752577,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"bN2tUs23MuzU","outputId":"7aded22e-4891-4c11-844c-63d8d531a00c"},"outputs":[],"source":["class Cait(nn.Module):\n","    def __init__(self, backbone, embedder, pretrained=True):\n","        super(Cait, self).__init__()\n","        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n","        self.backbone.reset_classifier(0)\n","        self.n_features = self.backbone.num_features\n","        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n","\n","    def forward(self, images):\n","        # features = (bs, embedding_size)\n","        features = self.backbone(images)\n","        # outputs  = (bs, num_classes)\n","        # if isinstance(features, tuple):\n","        #   features = features[0]\n","        output = self.fc(features)\n","        return output\n","\n","\n","cait224 = Cait('cait_s24_224',\n","            None,\n","            pretrained=False)\n","cait224.to(CONFIG['device']);"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9809,"status":"ok","timestamp":1642768762379,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"gidBPV8CMuzV","outputId":"596d9820-0abf-4550-cfdf-a09e52544782"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["wandb.restore('last.bin', 'jiwon7258/lg/5xzq9850', root='./')\n","cait224.load_state_dict(torch.load(\n","    'last.bin', map_location=CONFIG['device']))\n"]},{"cell_type":"markdown","metadata":{"id":"Wrj-hjzIMuzW"},"source":["## Swin S 224"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":3280,"status":"ok","timestamp":1642768765643,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"rvT1LFLEMuzW"},"outputs":[],"source":["class SwinS(nn.Module):\n","    def __init__(self, backbone, embedder, pretrained=True):\n","        super(SwinS, self).__init__()\n","        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n","        self.backbone.reset_classifier(0)\n","        self.n_features = self.backbone.num_features\n","        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n","\n","    def forward(self, images):\n","        # features = (bs, embedding_size)\n","        features = self.backbone(images)\n","        # outputs  = (bs, num_classes)\n","        # if isinstance(features, tuple):\n","        #   features = features[0]\n","        output = self.fc(features)\n","        return output\n","\n","\n","swinS224 = SwinS('swin_small_patch4_window7_224', None, pretrained=False)\n","swinS224.to(CONFIG['device']);\n"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10262,"status":"ok","timestamp":1642769549670,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"_gr-S379MuzX","outputId":"467c59c6-095d-4b44-c2aa-689580bf2e8a"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["MODEL_NAME = 'swin_small_224 finecutmixlast.bin'\n","RUN_PATH = 'jiwon7258/lg/3199pcx4'\n","wandb.restore(MODEL_NAME, RUN_PATH, root='./')\n","swinS224.load_state_dict(torch.load(\n","    MODEL_NAME, map_location=CONFIG['device']))\n"]},{"cell_type":"markdown","metadata":{"id":"0yb0wA5bMuzX"},"source":["## ConvNext Small 224"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3155,"status":"ok","timestamp":1642769552814,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"g0d2uydeMuzX","outputId":"b9f9393d-ddb5-4510-9774-bf52ef7d15cd"},"outputs":[{"data":{"text/plain":["ConvnextS(\n","  (backbone): ConvNeXt(\n","    (stem): Sequential(\n","      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n","      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n","    )\n","    (stages): Sequential(\n","      (0): ConvNeXtStage(\n","        (downsample): Identity()\n","        (blocks): Sequential(\n","          (0): ConvNeXtBlock(\n","            (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=96, out_features=384, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=384, out_features=96, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (1): ConvNeXtBlock(\n","            (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=96, out_features=384, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=384, out_features=96, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (2): ConvNeXtBlock(\n","            (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=96, out_features=384, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=384, out_features=96, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","        )\n","      )\n","      (1): ConvNeXtStage(\n","        (downsample): Sequential(\n","          (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n","          (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n","        )\n","        (blocks): Sequential(\n","          (0): ConvNeXtBlock(\n","            (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=192, out_features=768, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=768, out_features=192, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (1): ConvNeXtBlock(\n","            (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=192, out_features=768, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=768, out_features=192, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (2): ConvNeXtBlock(\n","            (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=192, out_features=768, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=768, out_features=192, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","        )\n","      )\n","      (2): ConvNeXtStage(\n","        (downsample): Sequential(\n","          (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n","          (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n","        )\n","        (blocks): Sequential(\n","          (0): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (1): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (2): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (3): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (4): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (5): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (6): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (7): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (8): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (9): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (10): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (11): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (12): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (13): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (14): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (15): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (16): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (17): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (18): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (19): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (20): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (21): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (22): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (23): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (24): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (25): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (26): ConvNeXtBlock(\n","            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","        )\n","      )\n","      (3): ConvNeXtStage(\n","        (downsample): Sequential(\n","          (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n","          (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n","        )\n","        (blocks): Sequential(\n","          (0): ConvNeXtBlock(\n","            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (1): ConvNeXtBlock(\n","            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","          (2): ConvNeXtBlock(\n","            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","              (act): GELU()\n","              (drop1): Dropout(p=0.0, inplace=False)\n","              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","              (drop2): Dropout(p=0.0, inplace=False)\n","            )\n","            (drop_path): Identity()\n","          )\n","        )\n","      )\n","    )\n","    (norm_pre): Identity()\n","    (head): Sequential(\n","      (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n","      (norm): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (drop): Dropout(p=0.0, inplace=False)\n","      (fc): Identity()\n","    )\n","  )\n","  (fc): Linear(in_features=768, out_features=25, bias=True)\n",")"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["class ConvnextS(nn.Module):\n","    def __init__(self, backbone, embedder, pretrained=True):\n","        super(ConvnextS, self).__init__()\n","        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n","        self.backbone.reset_classifier(0)\n","        self.n_features = self.backbone.num_features\n","        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n","\n","    def forward(self, images):\n","        # features = (bs, embedding_size)\n","        features = self.backbone(images)\n","        # outputs  = (bs, num_classes)\n","        # if isinstance(features, tuple):\n","        #   features = features[0]\n","        output = self.fc(features)\n","        return output\n","\n","\n","convnextS224 = ConvnextS('convnext_small', None, pretrained=False)\n","convnextS224.to(CONFIG['device'])\n"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10936,"status":"ok","timestamp":1642769563733,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"wWcAI_L5MuzY","outputId":"200934b3-7941-46ce-af15-ef992969fb00"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["MODEL_NAME = 'convnext_small finecutmixlast.bin'\n","RUN_PATH = 'jiwon7258/lg/2ow4king'\n","wandb.restore(MODEL_NAME, RUN_PATH, root='./')\n","convnextS224.load_state_dict(torch.load(\n","    MODEL_NAME, map_location=CONFIG['device']))\n"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":2348,"status":"ok","timestamp":1642769566059,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"7KAeBA4trKR7"},"outputs":[],"source":["models = {\n","    224 : [],\n","    384 : [],\n","    # 512 : [],\n","}\n","models[224].append(coatmini224)\n","models[224].append(convnextS224)\n","models[224].append(swinS224)\n","models[224].append(cait224)\n","models[224].append(beit224)\n","models[384].append(effnet)\n","models[384].append(swin)\n","models[384].append(deit)\n","# models[512].append(b4ns512)"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":2183,"status":"ok","timestamp":1642769568225,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"PsIBf2G4rKR8"},"outputs":[],"source":["# # TTA\n","# img_code_list = []\n","# outputs = []\n","# with torch.no_grad():\n","#     model.eval()\n","\n","#     bar = tqdm(enumerate(testDataloader), total=len(testDataloader))\n","\n","#     for step, (imgs, img_codes) in bar:\n","#         # imgs : (bs, N, C, H, W), torch.Tensor\n","#         # img_codes (bs, N), list(str)\n","#         imgs = imgs.to(CONFIG['device'])\n","#         imgs = rearrange(imgs, 'bs N C H W -> (bs N) C H W')\n","#         logits = model(imgs)\n","#         # logits : ( (bs * N), num_classes)\n","#         logits = logits.detach().cpu()\n","#         logits = rearrange(\n","#             logits, '(bs N) num_classes -> bs N num_classes', bs=CONFIG['valid_batch_size'])\n","#         output = np.argmax(torch.softmax(logits, dim=-1), axis=-1)\n","#         output = np.array(output)\n","#         # (bs, N)\n","#         output = stats.mode(output, axis=1)[0].reshape(-1)\n","#         # (bs)\n","#         output = [class_dict[i] for i in output]\n","\n","#         print(img_codes)\n","#         print(output)\n","\n","#         img_code_list.extend(img_codes)\n","#         outputs.extend(output)\n"]},{"cell_type":"markdown","metadata":{"id":"kQxfwOQiMuzZ"},"source":["# Inference"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7289156,"status":"ok","timestamp":1642776857372,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"HL-JTnnLrKR8","outputId":"91e109f8-c74b-4ed2-c7c5-c280e1845915"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3245/3245 [2:01:27<00:00,  2.25s/it]\n"]}],"source":["# no TTA\n","with torch.no_grad():\n","\n","    for model_list in models.values():\n","        for model in model_list :\n","            model.eval()\n","\n","    img_code_list = []\n","    outputs = []\n","        \n","    bar = tqdm(enumerate(testDataloader), total=len(testDataloader))\n","\n","    for step, (img_list, img_code) in bar:\n","        # img : list of (bs, C, H, W)\n","        # img_code : (bs)\n","        \n","        probs_list = []\n","        # list of (bs, num_classes)\n","\n","        for i, model_list in enumerate(models.values()):\n","            img= img_list[i]\n","            img = img.to(device)\n","            batch_size = img.shape[0]\n","        \n","            for model in model_list:\n","                logits = model(img)\n","                logits = logits.cpu()\n","                # (bs, num_classes)\n","                # 모델들마다 logit들의 값의 크기가 다를 수 있으므로, softmax를 이용해 정규화하는 작업이 필요하다\n","                prob = torch.softmax(logits, dim = -1)\n","                # (bs, num_classes)\n","                probs_list.append(prob)\n","            \n","        probs_list = torch.stack(probs_list)\n","        # (num_model, bs, num_clases)\n","        probs = torch.sum(probs_list, dim = 0)\n","        # (bs, num_classes)\n","\n","        output = np.argmax(torch.softmax(probs, dim=-1), axis=-1) # torch.Tensor, (bs,)\n","        output = np.array(output)\n","        output = [class_dict[i] for i in output]\n","\n","        img_code_list.extend(img_code)\n","        outputs.extend(output)\n","\n","        assert len(img_code_list) == len(outputs)\n","\n","\n"]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":3522,"status":"ok","timestamp":1642778094891,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"wRvZmcZ2rKR8"},"outputs":[],"source":["result = pd.DataFrame()\n","result['image'] = img_code_list\n","result['label'] = outputs\n","SUBMIT_FILE_NAME = 'finecutmix_effnetv2m_swin_deit_coatmini224_beit224in22k_cait224_swinS224_convnextS224.csv'\n","result.to_csv(SUBMIT_FILE_NAME,index= False, index_label=False)"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2561,"status":"ok","timestamp":1642778097443,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"JoeOAnxBrKR8","outputId":"73ee0201-70af-4ad5-82c0-89967e9ce957"},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["wandb.save(SUBMIT_FILE_NAME)\n"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["17fbbe2f0a804fab893b24d3390cf498"]},"executionInfo":{"elapsed":12357,"status":"ok","timestamp":1642778137555,"user":{"displayName":"강지원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17927617531452296238"},"user_tz":-540},"id":"0cJofdqLNMXW","outputId":"15b05a25-66e5-4972-c9e6-5db22af1c3ed"},"outputs":[{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 146... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17fbbe2f0a804fab893b24d3390cf498","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value=' 2.73MB of 2.73MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","</div><div class=\"wandb-col\">\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 35 artifact file(s) and 2 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">dashing-violet-88</strong>: <a href=\"https://wandb.ai/jiwon7258/lg/runs/3cvv61iw\" target=\"_blank\">https://wandb.ai/jiwon7258/lg/runs/3cvv61iw</a><br/>\n","Find logs at: <code>./wandb/run-20220121_121407-3cvv61iw/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["wandb.finish()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"lg_inf_Ensemble6.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
