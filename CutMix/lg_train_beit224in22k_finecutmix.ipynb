{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQuUKAHnPGqb"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:25:01.795688Z",
          "iopub.status.busy": "2022-01-15T10:25:01.794986Z",
          "iopub.status.idle": "2022-01-15T10:25:13.001673Z",
          "shell.execute_reply": "2022-01-15T10:25:13.000732Z",
          "shell.execute_reply.started": "2022-01-15T10:25:01.795591Z"
        },
        "id": "EP8Uk0lzPGqi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "! pip install wandb opencv-python-headless==4.1.2.30 albumentations torch-summary timm==0.5.4 einops joblib icecream  -qq -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:25:13.004437Z",
          "iopub.status.busy": "2022-01-15T10:25:13.004166Z",
          "iopub.status.idle": "2022-01-15T10:25:17.843442Z",
          "shell.execute_reply": "2022-01-15T10:25:17.842685Z",
          "shell.execute_reply.started": "2022-01-15T10:25:13.004400Z"
        },
        "id": "V8YpfugSPGqk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from glob import glob\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import urllib.request\n",
        "import csv\n",
        "import numpy as np\n",
        "from einops import rearrange, reduce, repeat\n",
        "from torch.cuda import amp\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "import time\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n",
        "import gc\n",
        "import os\n",
        "from icecream import ic\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "import cv2\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# For data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Pytorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda import amp\n",
        "\n",
        "# Utils\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sklearn Imports\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "\n",
        "import timm\n",
        "\n",
        "import json\n",
        "\n",
        "# Albumentations for augmentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# For colored terminal text\n",
        "from colorama import Fore, Back, Style\n",
        "c_ = Fore.CYAN\n",
        "sr_ = Style.RESET_ALL\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# For descriptive error messages\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVCBodi-PGql"
      },
      "source": [
        "# ENV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:25:17.845495Z",
          "iopub.status.busy": "2022-01-15T10:25:17.845230Z",
          "iopub.status.idle": "2022-01-15T10:25:17.893347Z",
          "shell.execute_reply": "2022-01-15T10:25:17.892018Z",
          "shell.execute_reply.started": "2022-01-15T10:25:17.845458Z"
        },
        "id": "fbOZOG8UPGqm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# ENV = 'COLAB'\n",
        "ENV = 'KAGGLE'\n",
        "# ENV = 'SYSTEM'\n",
        "\n",
        "# Option for Mixed Precision\n",
        "# FP16 = True\n",
        "FP16 = False\n",
        "\n",
        "\n",
        "CONFIG = dict(\n",
        "    note = \"finecutmix\",\n",
        "    nickname = 'BEiT 224 in22k fine cutmix',\n",
        "    seed=42,\n",
        "    backbone='beit_base_patch16_224_in22k',\n",
        "    embedder=None,\n",
        "    train_batch_size=16,\n",
        "    valid_batch_size=32,\n",
        "    img_size=224,\n",
        "    num_epochs=50,\n",
        "    early_stopping = False,\n",
        "    early_stopping_step = 5,\n",
        "    learning_rate=1e-4,\n",
        "    scheduler='CosineAnnealingLR',\n",
        "    min_lr=1e-6,\n",
        "    T_max=100,\n",
        "    num_classes = 25,\n",
        "    weight_decay=1e-6,\n",
        "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "    competition='lg',\n",
        "    _wandb_kernel='deb'\n",
        ")\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6BJH0gaPGqn"
      },
      "source": [
        "# SET SEED "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:25:17.896790Z",
          "iopub.status.busy": "2022-01-15T10:25:17.896189Z",
          "iopub.status.idle": "2022-01-15T10:25:17.909599Z",
          "shell.execute_reply": "2022-01-15T10:25:17.908786Z",
          "shell.execute_reply.started": "2022-01-15T10:25:17.896748Z"
        },
        "id": "Vj7acIAIPGqn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "\n",
        "set_seed(CONFIG['seed'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KA00McmPGqo"
      },
      "source": [
        "# Read the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "execution": {
          "iopub.execute_input": "2022-01-15T10:25:17.911360Z",
          "iopub.status.busy": "2022-01-15T10:25:17.910859Z",
          "iopub.status.idle": "2022-01-15T10:28:30.802857Z",
          "shell.execute_reply": "2022-01-15T10:28:30.801968Z",
          "shell.execute_reply.started": "2022-01-15T10:25:17.911319Z"
        },
        "id": "jKC4FDfyPGqp",
        "outputId": "5e7fb029-94e9-402c-de62-96cabf62aa67",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiwon7258\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    Resuming run <strong><a href=\"https://wandb.ai/jiwon7258/lg/runs/1vkrdmyp\" target=\"_blank\">BEiT 224 in22k finecutmix</a></strong> to <a href=\"https://wandb.ai/jiwon7258/lg\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact lg_train:v0, 918.24MB. 17301 files... Done. 0:0:0\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "run = wandb.init(project=\"lg\",\n",
        "                 entity=\"jiwon7258\",\n",
        "                 config=CONFIG,\n",
        "                 job_type='train',\n",
        "                 id = '1vkrdmyp',\n",
        "                 resume= 'must',\n",
        "                 )\n",
        "dataset = wandb.run.use_artifact(\n",
        "    'jiwon7258/lg/lg_train:v0', type='dataset')\n",
        "\n",
        "run.name = CONFIG['nickname']\n",
        "\n",
        "# Download the artifact's contents\n",
        "dataset_dir = dataset.download()\n",
        "dataset_dir = Path(dataset_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:28:30.804754Z",
          "iopub.status.busy": "2022-01-15T10:28:30.804383Z",
          "iopub.status.idle": "2022-01-15T10:28:30.809944Z",
          "shell.execute_reply": "2022-01-15T10:28:30.809259Z",
          "shell.execute_reply.started": "2022-01-15T10:28:30.804698Z"
        },
        "id": "ca-5DetEPGqq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH = dataset_dir\n",
        "# TEST_PATH = dataset_dir / 'test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-8x5P--PGqr"
      },
      "source": [
        "# Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:28:30.813928Z",
          "iopub.status.busy": "2022-01-15T10:28:30.811190Z",
          "iopub.status.idle": "2022-01-15T10:28:30.822155Z",
          "shell.execute_reply": "2022-01-15T10:28:30.821435Z",
          "shell.execute_reply.started": "2022-01-15T10:28:30.813872Z"
        },
        "id": "Qetw9jGjPGqr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "    \"train\": A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.15,\n",
        "                           rotate_limit=35, p=0.5),\n",
        "        A.RGBShift(r_shift_limit=15, g_shift_limit=15,\n",
        "                   b_shift_limit=15, p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.5),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.Normalize(),\n",
        "        ToTensorV2()], p=1.),\n",
        "\n",
        "    \"valid\": A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.Normalize(),\n",
        "        ToTensorV2()], p=1.)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF_SM2DGPGqs"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:28:30.825534Z",
          "iopub.status.busy": "2022-01-15T10:28:30.824486Z",
          "iopub.status.idle": "2022-01-15T10:28:31.525603Z",
          "shell.execute_reply": "2022-01-15T10:28:31.524866Z",
          "shell.execute_reply.started": "2022-01-15T10:28:30.825498Z"
        },
        "id": "XW2BnvG6PGqs",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_csv = sorted(glob(str(TRAIN_PATH / '*/*.csv')))\n",
        "train_jpg = sorted(glob(str(TRAIN_PATH / '*/*.jpg')))\n",
        "train_json = sorted(glob(str(TRAIN_PATH / '*/*.json')))\n",
        "\n",
        "\n",
        "crops = []\n",
        "diseases = []\n",
        "risks = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(train_json)):\n",
        "    with open(train_json[i], 'r') as f:\n",
        "        sample = json.load(f)\n",
        "        crop = sample['annotations']['crop']\n",
        "        disease = sample['annotations']['disease']\n",
        "        risk = sample['annotations']['risk']\n",
        "        label=f\"{crop}_{disease}_{risk}\"\n",
        "    \n",
        "        crops.append(crop)\n",
        "        diseases.append(disease)\n",
        "        risks.append(risk)\n",
        "        labels.append(label)\n",
        "        \n",
        "label_unique = sorted(np.unique(labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
        "\n",
        "train_labels = [label_unique[k] for k in labels] # len = train_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIQNMAQ_PGqt"
      },
      "outputs": [],
      "source": [
        "train_jpg = np.array(train_jpg)\n",
        "train_labels = np.array(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:28:31.562715Z",
          "iopub.status.busy": "2022-01-15T10:28:31.562438Z",
          "iopub.status.idle": "2022-01-15T10:28:31.587681Z",
          "shell.execute_reply": "2022-01-15T10:28:31.586382Z",
          "shell.execute_reply.started": "2022-01-15T10:28:31.562681Z"
        },
        "id": "40-6mAVePGqt",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, train_img, train_label, transforms=None):\n",
        "        self.imgs = train_img\n",
        "        self.labels = train_label\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.imgs[index]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        target = self.labels[index]\n",
        "        \n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)[\"image\"]\n",
        "            \n",
        "        return img, target\n",
        "    \n",
        "# trainDataset = CustomDataset(X_train, y_train, transforms = data_transforms['train'])\n",
        "# trainDataloader = DataLoader(\n",
        "#     trainDataset, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
        "\n",
        "# validDataset = CustomDataset(X_val, y_val, transforms = data_transforms['valid'])\n",
        "# validDataloader = DataLoader(validDataset, batch_size = CONFIG['valid_batch_size'], shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TucH1uf_PGqu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "train_datasets = []\n",
        "valid_datasets = []\n",
        "train_dataloaders = []\n",
        "valid_dataloaders = []\n",
        "\n",
        "skf = StratifiedKFold(n_splits = 5)\n",
        "\n",
        "for step, (train_index, val_index) in enumerate(skf.split(X = train_jpg, y= train_labels)):\n",
        "    X_train = train_jpg[train_index]\n",
        "    y_train = train_labels[train_index]\n",
        "    X_val = train_jpg[val_index]\n",
        "    y_val = train_labels[val_index]\n",
        "    train_datasets.append(CustomDataset(\n",
        "        X_train, y_train, transforms=data_transforms['train']))\n",
        "    valid_datasets.append(CustomDataset(\n",
        "        X_val, y_val, transforms=data_transforms['valid']))\n",
        "    train_dataloaders.append(DataLoader(\n",
        "        train_datasets[step], batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
        "    )\n",
        "    valid_dataloaders.append(\n",
        "        DataLoader(\n",
        "            valid_datasets[step], batch_size=CONFIG['valid_batch_size'], shuffle=True)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qquyNic-PGqu"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "execution": {
          "iopub.execute_input": "2022-01-15T10:28:31.595710Z",
          "iopub.status.busy": "2022-01-15T10:28:31.592703Z",
          "iopub.status.idle": "2022-01-15T10:29:04.375344Z",
          "shell.execute_reply": "2022-01-15T10:29:04.374595Z",
          "shell.execute_reply.started": "2022-01-15T10:28:31.595662Z"
        },
        "id": "EeRw9VshPGqv",
        "outputId": "ed21a587-444a-4621-b0f8-837721e73a8c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, backbone, embedder, pretrained=True):\n",
        "        super(Model, self).__init__()\n",
        "        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n",
        "        self.backbone.reset_classifier(0)\n",
        "        self.n_features = self.backbone.num_features\n",
        "        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n",
        "\n",
        "    def forward(self, images):\n",
        "        # features = (bs, embedding_size)\n",
        "        features = self.backbone(images)\n",
        "        # outputs  = (bs, num_classes)\n",
        "        # if isinstance(features, tuple):\n",
        "        #   features = features[0]\n",
        "        output = self.fc(features)\n",
        "        return output\n",
        "\n",
        "\n",
        "model = Model(CONFIG['backbone'], CONFIG['embedder'], pretrained = True)\n",
        "model.to(CONFIG['device'])\n",
        ";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:29:04.376696Z",
          "iopub.status.busy": "2022-01-15T10:29:04.376445Z",
          "iopub.status.idle": "2022-01-15T10:29:04.383964Z",
          "shell.execute_reply": "2022-01-15T10:29:04.383287Z",
          "shell.execute_reply.started": "2022-01-15T10:29:04.376660Z"
        },
        "id": "5yml5ZPPPGqv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "    params=model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:29:04.385682Z",
          "iopub.status.busy": "2022-01-15T10:29:04.385257Z",
          "iopub.status.idle": "2022-01-15T10:29:05.537793Z",
          "shell.execute_reply": "2022-01-15T10:29:05.536741Z",
          "shell.execute_reply.started": "2022-01-15T10:29:04.385649Z"
        },
        "id": "iIKSttnGPGqv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def criterion(logits: torch.tensor, targets: torch.tensor):\n",
        "    return nn.CrossEntropyLoss()(logits.view(-1,CONFIG['num_classes']), targets.view(-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EitMMfqvNfi9"
      },
      "outputs": [],
      "source": [
        "def criterion_prob(logits: torch.tensor, targets: torch.tensor):\n",
        "    return nn.CrossEntropyLoss()(logits.view(-1,CONFIG['num_classes']), targets.view(-1,CONFIG['num_classes']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABmaMZ2yNfi9"
      },
      "source": [
        "# CutMix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC3atotnNfi-"
      },
      "outputs": [],
      "source": [
        "def cutmix(img, target):\n",
        "    \"\"\" \n",
        "    img : (bs, C, H, W)\n",
        "    target\n",
        "        - (bs,)\n",
        "        - integer scalar\n",
        "    \"\"\"\n",
        "    batch_size, C, H, W, = img.shape\n",
        "    # ic(img.shape)\n",
        "\n",
        "    img_a = img\n",
        "    target_a = target\n",
        "    img_b = img\n",
        "    target_b = target\n",
        "\n",
        "    mask = np.arange(batch_size)\n",
        "    mask = np.random.permutation(mask)\n",
        "    # ic(mask)\n",
        "    img_b = img_a[mask]\n",
        "    target_b = target_a[mask]\n",
        "    # ic(target, target_b)\n",
        "\n",
        "    lam = np.random.uniform(low=0, high=1)\n",
        "    r_x = np.random.uniform(low=0, high=W)\n",
        "    r_y = np.random.uniform(low=0, high=H)\n",
        "    r_w = W * np.sqrt(1 - lam)\n",
        "    r_h = H * np.sqrt(1 - lam)\n",
        "    ic(lam, r_x, r_y, r_w, r_h)\n",
        "    x1 = np.int(np.clip((r_x - r_w) / 2, 0, W))\n",
        "    x2 = np.int(np.clip((r_x + r_w) / 2, 0, W))\n",
        "    y1 = np.int(np.clip((r_y - r_h) / 2, 0, H))\n",
        "    y2 = np.int(np.clip((r_y + r_h) / 2, 0, H))\n",
        "    ic(x1, x2, y1, y2)\n",
        "\n",
        "    img_a[:, :, y1:y2, x1:x2] = img_b[:, :, y1:y2, x1:x2]\n",
        "\n",
        "    # Adjust lambda to exact ratio\n",
        "\n",
        "    lam = 1 - (x2 - x1) * (y2 - y1) / float(W * H)\n",
        "\n",
        "    return img_a, target_b, lam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MJ1ibK_Nfi-"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(target, num_class) -> torch.Tensor:\n",
        "    \"\"\"  \n",
        "    INPUT\n",
        "    target\n",
        "        - (bs,)\n",
        "\n",
        "    OUTPUT\n",
        "        target\n",
        "            - (bs, num_class)\n",
        "            - one hot encoded vector\n",
        "    \"\"\"\n",
        "    target = np.array(target)\n",
        "    batch_size = target.shape[0]\n",
        "\n",
        "    result = np.zeros(shape=(batch_size, num_class))\n",
        "\n",
        "    for i, ground_truth in enumerate(target):\n",
        "        result[i, ground_truth] = 1\n",
        "\n",
        "    result = torch.Tensor(result)\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0omce9FPGqw"
      },
      "source": [
        "   # Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:33:47.356814Z",
          "iopub.status.busy": "2022-01-15T10:33:47.356540Z",
          "iopub.status.idle": "2022-01-15T10:33:47.375626Z",
          "shell.execute_reply": "2022-01-15T10:33:47.373734Z",
          "shell.execute_reply.started": "2022-01-15T10:33:47.356781Z"
        },
        "id": "aC6ChxxqPGqw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
        "    # train 모드로 변경\n",
        "    model.train()\n",
        "\n",
        "    # for the Mixed Precision\n",
        "    # Pytorch 예제 : https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples\n",
        "    if(FP16):\n",
        "        scaler = amp.GradScaler()\n",
        "\n",
        "    losses = AverageMeter()\n",
        "    accuracy = AverageMeter()\n",
        "    f1 = AverageMeter()\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "\n",
        "    for step, (img, target) in bar:\n",
        "        img, target_b, lam = cutmix(img, target)\n",
        "\n",
        "        img = img.to(device)\n",
        "        target = target.to(device)\n",
        "        target_b = target_b.to(device)\n",
        "\n",
        "        batch_size = img.shape[0]\n",
        "\n",
        "        if(FP16):\n",
        "            with amp.autocast(enabled=True):\n",
        "                logits = model(img)\n",
        "                loss = criterion_prob(logits, target)\n",
        "\n",
        "                # loss를 Scale\n",
        "                # Scaled Grdients를 계산(call)하기 위해 scaled loss를 backward()\n",
        "                scaler.scale(loss).backward()\n",
        "                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "                # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
        "                # otherwise, optimizer.step() is skipped.\n",
        "                scaler.step(optimizer)\n",
        "\n",
        "                # Updates the scale for next iteration.\n",
        "                scaler.update()\n",
        "\n",
        "        else:\n",
        "            logits = model(img)\n",
        "            probs = torch.softmax(logits, dim = -1)\n",
        "            loss = criterion(logits, target) * lam + criterion(logits, target_b) * (1-lam)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "            optimizer.step()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # change learning rate by Scheduler\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        # loss.item()은 loss를 Python Float으로 반환\n",
        "        losses.update(loss.item())\n",
        "\n",
        "        # logits\n",
        "        logits = logits.detach().cpu()\n",
        "\n",
        "        # acc, f1\n",
        "        if (lam >= 0.5) :\n",
        "            output = np.argmax(torch.softmax(logits, dim = -1), axis = -1)\n",
        "            step_acc = np.mean(\n",
        "                output.view(-1).numpy() == target.view(-1).detach().cpu().numpy())\n",
        "            step_f1 = f1_score(output.view(-1).numpy(),\n",
        "                            target.view(-1).detach().cpu().numpy(),average='macro')\n",
        "        else :\n",
        "            output = np.argmax(torch.softmax(logits, dim=-1), axis=-1)\n",
        "            step_acc = np.mean(\n",
        "                output.view(-1).numpy() == target_b.view(-1).detach().cpu().numpy())\n",
        "            step_f1 = f1_score(output.view(-1).numpy(),\n",
        "                               target_b.view(-1).detach().cpu().numpy(), average='macro')\n",
        "\n",
        "                  \n",
        "        accuracy.update(step_acc)\n",
        "        f1.update(step_f1)\n",
        "\n",
        "        # loss\n",
        "        train_loss = losses.avg\n",
        "        train_acc = accuracy.avg\n",
        "        train_f1 = f1.avg\n",
        "\n",
        "        bar.set_postfix(\n",
        "            Epoch=epoch, Train_Loss=train_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy= train_acc, f1 = train_f1\n",
        "        )\n",
        "\n",
        "    # Garbage Collector\n",
        "    gc.collect()\n",
        "\n",
        "    return losses.avg, accuracy.avg, f1.avg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csIOYVOxPGqx"
      },
      "source": [
        "   # Validation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:33:47.378229Z",
          "iopub.status.busy": "2022-01-15T10:33:47.377682Z",
          "iopub.status.idle": "2022-01-15T10:33:47.393570Z",
          "shell.execute_reply": "2022-01-15T10:33:47.392783Z",
          "shell.execute_reply.started": "2022-01-15T10:33:47.378191Z"
        },
        "id": "QLhONiwOPGqx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model, dataloader, device, epoch):\n",
        "    model.eval()\n",
        "\n",
        "    losses = AverageMeter()\n",
        "    accuracy = AverageMeter()\n",
        "    f1 = AverageMeter()\n",
        "\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "\n",
        "    for step, (img, target) in bar:\n",
        "        img = img.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        batch_size = img.shape[0]\n",
        "\n",
        "        logits = model(img)\n",
        "        loss = criterion(logits, target)\n",
        "\n",
        "        # loss.item()은 loss를 Python Float으로 반환\n",
        "        losses.update(loss.item())\n",
        "\n",
        "        # logits\n",
        "        logits = logits.detach().cpu()\n",
        "        \n",
        "        output = np.argmax(torch.softmax(logits, dim=-1), axis=-1)\n",
        "        step_acc = np.mean(\n",
        "            output.view(-1).numpy() == target.view(-1).detach().cpu().numpy())\n",
        "        step_f1 = f1_score(output.view(-1).numpy(),\n",
        "                           target.view(-1).detach().cpu().numpy(), average='macro')\n",
        "\n",
        "        accuracy.update(step_acc)\n",
        "        f1.update(step_f1)\n",
        "\n",
        "        # loss\n",
        "        val_loss = losses.avg\n",
        "        val_acc = accuracy.avg\n",
        "        val_f1 = f1.avg\n",
        "\n",
        "        bar.set_postfix(\n",
        "            Epoch=epoch, Valid_Loss=val_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy=val_acc, f1 = val_f1\n",
        "        )\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    return losses.avg, accuracy.avg, f1.avg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:33:47.395930Z",
          "iopub.status.busy": "2022-01-15T10:33:47.395337Z",
          "iopub.status.idle": "2022-01-15T10:33:47.415192Z",
          "shell.execute_reply": "2022-01-15T10:33:47.414280Z",
          "shell.execute_reply.started": "2022-01-15T10:33:47.395894Z"
        },
        "id": "jZfZNPdfPGqx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "START_EPOCH = 0\n",
        "\n",
        "\n",
        "def run_training(\n",
        "    model,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    device,\n",
        "    num_epochs,\n",
        "    metric_prefix=\"\",\n",
        "    file_prefix=\"\",\n",
        "    early_stopping=True,\n",
        "    early_stopping_step=10,\n",
        "):\n",
        "    # To automatically log graidents\n",
        "    wandb.watch(model, log_freq=100)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU:{}\\n\".format(torch.cuda.get_device_name()))\n",
        "\n",
        "    start = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = np.inf\n",
        "    history = defaultdict(list)\n",
        "    early_stop_counter = 0\n",
        "    global START_EPOCH\n",
        "\n",
        "    # num_epochs만큼, train과 val을 실행한다\n",
        "    for epoch in range(START_EPOCH, START_EPOCH + num_epochs):\n",
        "        gc.collect()\n",
        "\n",
        "        fold_num = 5\n",
        "        fold = epoch % fold_num\n",
        "\n",
        "\n",
        "        trainDataloader = train_dataloaders[fold]\n",
        "        validDataloader = valid_dataloaders[fold]\n",
        "\n",
        "        train_train_loss, train_accuracy, train_f1 = train_one_epoch(\n",
        "            model,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            dataloader=trainDataloader,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "        )\n",
        "\n",
        "        val_loss, val_accuracy, val_f1 = valid_one_epoch(\n",
        "            model, validDataloader, device=device, epoch=epoch\n",
        "        )\n",
        "\n",
        "\n",
        "        history[f\"{metric_prefix}Train Loss\"].append(train_train_loss)\n",
        "        history[f\"{metric_prefix}Train Accuracy\"].append(train_accuracy)\n",
        "        history[f\"{metric_prefix}Train F1\"].append(train_f1)\n",
        "        history[f\"{metric_prefix}Valid Loss\"].append(val_loss)\n",
        "        history[f\"{metric_prefix}Valid Accuracy\"].append(val_accuracy)\n",
        "        history[f\"{metric_prefix}Valid F1\"].append(val_f1)\n",
        "\n",
        "        # Log the metrics\n",
        "        wandb.log(\n",
        "            {\n",
        "                f\"{metric_prefix}Train Loss\": train_train_loss,\n",
        "                f\"{metric_prefix}Valid Loss\": val_loss,\n",
        "                f\"{metric_prefix}Train Accuracy\": train_accuracy,\n",
        "                f\"{metric_prefix}Valid Accuracy\": val_accuracy,\n",
        "                f\"{metric_prefix}Train F1\": train_f1,\n",
        "                f\"{metric_prefix}Valid F1\": val_f1,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        print(f\"Valid Loss : {val_loss}\")\n",
        "\n",
        "        torch.save(model.state_dict(), f'{CONFIG[\"backbone\"]}_last.bin')\n",
        "        wandb.save(f'{CONFIG[\"backbone\"]}_last.bin')\n",
        "\n",
        "        # deep copy the model\n",
        "        if val_loss <= best_loss:\n",
        "            early_stop_counter = 0\n",
        "\n",
        "            print(\n",
        "                f\"Validation Loss improved( {best_loss} ---> {val_loss}  )\"\n",
        "            )\n",
        "\n",
        "            # Update Best Loss\n",
        "            best_loss = val_loss\n",
        "\n",
        "            # Update Best Model Weight\n",
        "            # run.summary['Best RMSE'] = best_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            PATH = \"{}epoch{:.0f}_Loss{:.4f}.bin\".format(\n",
        "                file_prefix, epoch, best_loss)\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            torch.save(model.state_dict(),\n",
        "                       f\"{file_prefix}best_{epoch}epoch.bin\")\n",
        "            # Save a model file from the current directory\n",
        "            wandb.save(PATH)\n",
        "\n",
        "            print(f\"Model Saved\")\n",
        "\n",
        "        elif early_stopping:\n",
        "            early_stop_counter += 1\n",
        "            if early_stop_counter > early_stopping_step:\n",
        "                break\n",
        "\n",
        "        START_EPOCH = epoch + 1\n",
        "        # break\n",
        "\n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "    print(\n",
        "        \"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n",
        "            time_elapsed // 3600,\n",
        "            (time_elapsed % 3600) // 60,\n",
        "            (time_elapsed % 3600) % 60,\n",
        "        )\n",
        "    )\n",
        "    print(\"Best Loss: {:.4f}\".format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-01-15T10:33:47.416354Z",
          "iopub.status.busy": "2022-01-15T10:33:47.416056Z",
          "iopub.status.idle": "2022-01-15T10:33:48.692352Z",
          "shell.execute_reply": "2022-01-15T10:33:48.691550Z",
          "shell.execute_reply.started": "2022-01-15T10:33:47.416328Z"
        },
        "id": "eX2s0GMOPGqy",
        "outputId": "b161ab94-848f-474a-b2f6-67cf87ac6199",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.restore('epoch55_Loss0.0000.bin', 'jiwon7258/lg/1u03kks6', root='./')\n",
        "model.load_state_dict(torch.load('epoch55_Loss0.0000.bin',\n",
        "                      map_location=CONFIG['device']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDi14R3uPGqz"
      },
      "source": [
        "# Reduced LR (1e-6) : 50epochs (~60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5G3qhmFPGqz"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "    params=model.parameters(), lr=1e-6, weight_decay=CONFIG['weight_decay'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae1QgOXSPGqz"
      },
      "outputs": [],
      "source": [
        "for param in model.backbone.named_parameters():\n",
        "    param[1].requires_grad = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dKXcxeLEPGq0",
        "outputId": "bc423876-edb4-465a-b188-c86464781b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Using GPU:Tesla P100-PCIE-16GB\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 289/289 [02:31<00:00,  1.91it/s, Epoch=0, LR=1e-6, Train_Loss=2.55, accuracy=0.804, f1=0.747]\n",
            "100%|██████████| 37/37 [00:16<00:00,  2.30it/s, Epoch=0, LR=1e-6, Valid_Loss=1.2e-5, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 1.1997625571134914e-05\n",
            "Validation Loss improved( inf ---> 1.1997625571134914e-05  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 289/289 [02:32<00:00,  1.90it/s, Epoch=1, LR=1e-6, Train_Loss=2.55, accuracy=0.812, f1=0.764]\n",
            "100%|██████████| 37/37 [00:15<00:00,  2.43it/s, Epoch=1, LR=1e-6, Valid_Loss=1.38e-5, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 1.3833102960106425e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 289/289 [02:34<00:00,  1.87it/s, Epoch=2, LR=1e-6, Train_Loss=2.55, accuracy=0.823, f1=0.777]\n",
            "100%|██████████| 37/37 [00:15<00:00,  2.43it/s, Epoch=2, LR=1e-6, Valid_Loss=0.000564, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0005640735684098075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 289/289 [02:32<00:00,  1.89it/s, Epoch=3, LR=1e-6, Train_Loss=2.53, accuracy=0.836, f1=0.797]\n",
            "100%|██████████| 37/37 [00:15<00:00,  2.42it/s, Epoch=3, LR=1e-6, Valid_Loss=1.05e-5, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 1.0533618371475885e-05\n",
            "Validation Loss improved( 1.1997625571134914e-05 ---> 1.0533618371475885e-05  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 289/289 [02:31<00:00,  1.90it/s, Epoch=4, LR=1e-6, Train_Loss=2.53, accuracy=0.856, f1=0.815]\n",
            "100%|██████████| 37/37 [00:15<00:00,  2.42it/s, Epoch=4, LR=1e-6, Valid_Loss=7.51e-6, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 7.512897246044512e-06\n",
            "Validation Loss improved( 1.0533618371475885e-05 ---> 7.512897246044512e-06  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 289/289 [02:31<00:00,  1.90it/s, Epoch=5, LR=1e-6, Train_Loss=2.52, accuracy=0.842, f1=0.801]\n",
            "100%|██████████| 37/37 [00:15<00:00,  2.44it/s, Epoch=5, LR=1e-6, Valid_Loss=6.13e-6, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 6.134257345386407e-06\n",
            "Validation Loss improved( 7.512897246044512e-06 ---> 6.134257345386407e-06  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 289/289 [02:31<00:00,  1.91it/s, Epoch=6, LR=1e-6, Train_Loss=2.53, accuracy=0.831, f1=0.797]\n",
            "100%|██████████| 37/37 [00:15<00:00,  2.43it/s, Epoch=6, LR=1e-6, Valid_Loss=1.2e-5, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 1.2034485543346308e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 289/289 [02:31<00:00,  1.91it/s, Epoch=7, LR=1e-6, Train_Loss=2.54, accuracy=0.873, f1=0.829]\n",
            "100%|██████████| 37/37 [00:15<00:00,  2.46it/s, Epoch=7, LR=1e-6, Valid_Loss=0.000142, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.00014180178651577828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 289/289 [02:31<00:00,  1.91it/s, Epoch=8, LR=1e-6, Train_Loss=2.53, accuracy=0.845, f1=0.807]\n",
            "100%|██████████| 37/37 [00:15<00:00,  2.45it/s, Epoch=8, LR=1e-6, Valid_Loss=8.49e-6, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 8.489413841352705e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 289/289 [02:31<00:00,  1.91it/s, Epoch=9, LR=1e-6, Train_Loss=2.53, accuracy=0.837, f1=0.797]\n",
            "100%|██████████| 37/37 [00:15<00:00,  2.44it/s, Epoch=9, LR=1e-6, Valid_Loss=5.96e-6, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 5.957617803246416e-06\n",
            "Validation Loss improved( 6.134257345386407e-06 ---> 5.957617803246416e-06  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 289/289 [02:32<00:00,  1.89it/s, Epoch=10, LR=1e-6, Train_Loss=2.54, accuracy=0.85, f1=0.817]\n",
            "100%|██████████| 37/37 [00:15<00:00,  2.42it/s, Epoch=10, LR=1e-6, Valid_Loss=6.3e-6, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 6.3039651527728506e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 4/289 [00:02<03:22,  1.41it/s, Epoch=11, LR=1e-6, Train_Loss=2.64, accuracy=0.891, f1=0.796]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-7a00d0c9f21d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfile_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'early_stopping'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mearly_stopping_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'early_stopping_step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m );\n",
            "\u001b[0;32m<ipython-input-20-a621bf777253>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, optimizer, scheduler, device, num_epochs, metric_prefix, file_prefix, early_stopping, early_stopping_step)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainDataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         )\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-c6de2021919e>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, scheduler, dataloader, device, epoch)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mone_hot_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "run_training(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    # scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    #     optimizer=optimizer, T_max=CONFIG['T_max'], eta_min=CONFIG['min_lr']),\n",
        "    scheduler=None,\n",
        "    device=device,\n",
        "    num_epochs=CONFIG['num_epochs'],\n",
        "    metric_prefix=\"\",\n",
        "    file_prefix=\"\",\n",
        "    early_stopping=CONFIG['early_stopping'],\n",
        "    early_stopping_step=CONFIG['early_stopping_step'],\n",
        ");\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M3GFix51ildm",
        "outputId": "59afbbac-50a1-4fba-9a21-76688e9c639d"
      },
      "outputs": [
        {
          "ename": "Exception",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a2bce46dc485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(exit_code, quiet)\u001b[0m\n\u001b[1;32m   2846\u001b[0m     \"\"\"\n\u001b[1;32m   2847\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2848\u001b[0;31m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexit_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexit_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_teardown_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTeardownStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEARLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m                 \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atexit_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexit_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_jupyter_teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code and history: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cleaning up jupyter logic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mlog_code\u001b[0;34m(self, root, name, include_fn, exclude_fn)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiles_added\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mlog_artifact\u001b[0;34m(self, artifact_or_path, name, type, aliases)\u001b[0m\n\u001b[1;32m   2484\u001b[0m             \u001b[0mAn\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mArtifact\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \"\"\"\n\u001b[0;32m-> 2486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maliases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m     def upsert_artifact(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_log_artifact\u001b[0;34m(self, artifact_or_path, name, type, aliases, distributed_id, finalize, is_user_created, use_after_commit)\u001b[0m\n\u001b[1;32m   2626\u001b[0m                     \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2627\u001b[0m                     \u001b[0mis_user_created\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_user_created\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2628\u001b[0;31m                     \u001b[0muse_after_commit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_after_commit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2629\u001b[0m                 )\n\u001b[1;32m   2630\u001b[0m                 \u001b[0martifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_artifact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LazyArtifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_public_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mcommunicate_artifact\u001b[0;34m(self, run, artifact, aliases, is_user_created, use_after_commit, finalize)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mlog_artifact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogArtifactRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mlog_artifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto_artifact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_communicate_artifact\u001b[0;34m(self, log_artifact)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_communicate_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_artifact\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogArtifactRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     def _communicate_artifact_send(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_communicate_async\u001b[0;34m(self, rec, local)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_router\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_router\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_and_receive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread NetStatThr:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\", line 152, in check_network_status\n",
            "    status_response = self._interface.communicate_network_status()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\", line 125, in communicate_network_status\n",
            "    resp = self._communicate_network_status(status)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\", line 388, in _communicate_network_status\n",
            "    resp = self._communicate(req, local=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\", line 213, in _communicate\n",
            "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\", line 218, in _communicate_async\n",
            "    raise Exception(\"The wandb backend process has shutdown\")\n",
            "Exception: The wandb backend process has shutdown\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f607414d7d0>> (for post_run_cell):\n"
          ]
        },
        {
          "ename": "Exception",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;31m# Attempt to save the code on every execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_ipynb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mlog_code\u001b[0;34m(self, root, name, include_fn, exclude_fn)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiles_added\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mlog_artifact\u001b[0;34m(self, artifact_or_path, name, type, aliases)\u001b[0m\n\u001b[1;32m   2484\u001b[0m             \u001b[0mAn\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mArtifact\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \"\"\"\n\u001b[0;32m-> 2486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maliases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m     def upsert_artifact(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_log_artifact\u001b[0;34m(self, artifact_or_path, name, type, aliases, distributed_id, finalize, is_user_created, use_after_commit)\u001b[0m\n\u001b[1;32m   2626\u001b[0m                     \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2627\u001b[0m                     \u001b[0mis_user_created\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_user_created\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2628\u001b[0;31m                     \u001b[0muse_after_commit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_after_commit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2629\u001b[0m                 )\n\u001b[1;32m   2630\u001b[0m                 \u001b[0martifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_artifact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LazyArtifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_public_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mcommunicate_artifact\u001b[0;34m(self, run, artifact, aliases, is_user_created, use_after_commit, finalize)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mlog_artifact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogArtifactRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mlog_artifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto_artifact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_communicate_artifact\u001b[0;34m(self, log_artifact)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_communicate_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_artifact\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogArtifactRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     def _communicate_artifact_send(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_communicate_async\u001b[0;34m(self, rec, local)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_router\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_router\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_and_receive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
          ]
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "lg_train_beit224in22k_finecutmix.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
