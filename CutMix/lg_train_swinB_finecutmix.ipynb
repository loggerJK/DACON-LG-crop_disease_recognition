{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSwfe97d7Hzw"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-01-15T10:25:01.795688Z",
          "iopub.status.busy": "2022-01-15T10:25:01.794986Z",
          "iopub.status.idle": "2022-01-15T10:25:13.001673Z",
          "shell.execute_reply": "2022-01-15T10:25:13.000732Z",
          "shell.execute_reply.started": "2022-01-15T10:25:01.795591Z"
        },
        "id": "rUtEkb1b7Hz1",
        "outputId": "8f0df211-67b0-4979-c8fd-7b12f957eac7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 13.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 102 kB 70.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 431 kB 78.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 9.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 143 kB 69.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 72.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.6 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install wandb opencv-python-headless==4.1.2.30 albumentations torch-summary timm einops joblib icecream  -qq -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:25:13.004437Z",
          "iopub.status.busy": "2022-01-15T10:25:13.004166Z",
          "iopub.status.idle": "2022-01-15T10:25:17.843442Z",
          "shell.execute_reply": "2022-01-15T10:25:17.842685Z",
          "shell.execute_reply.started": "2022-01-15T10:25:13.004400Z"
        },
        "id": "Kb0ITUqO7Hz3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from glob import glob\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import urllib.request\n",
        "import csv\n",
        "import numpy as np\n",
        "from einops import rearrange, reduce, repeat\n",
        "from torch.cuda import amp\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "import time\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n",
        "import gc\n",
        "import os\n",
        "from icecream import ic\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "import cv2\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# For data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Pytorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda import amp\n",
        "\n",
        "# Utils\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sklearn Imports\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "\n",
        "import timm\n",
        "\n",
        "import json\n",
        "\n",
        "# Albumentations for augmentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# For colored terminal text\n",
        "from colorama import Fore, Back, Style\n",
        "c_ = Fore.CYAN\n",
        "sr_ = Style.RESET_ALL\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# For descriptive error messages\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNnCIXzh7Hz5"
      },
      "source": [
        "# ENV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:25:17.845495Z",
          "iopub.status.busy": "2022-01-15T10:25:17.845230Z",
          "iopub.status.idle": "2022-01-15T10:25:17.893347Z",
          "shell.execute_reply": "2022-01-15T10:25:17.892018Z",
          "shell.execute_reply.started": "2022-01-15T10:25:17.845458Z"
        },
        "id": "U_1cy9hb7Hz6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# ENV = 'COLAB'\n",
        "ENV = 'KAGGLE'\n",
        "# ENV = 'SYSTEM'\n",
        "\n",
        "# Option for Mixed Precision\n",
        "# FP16 = True\n",
        "FP16 = False\n",
        "\n",
        "\n",
        "CONFIG = dict(\n",
        "    seed=42,\n",
        "    nickname = 'SwinB finecutmix',\n",
        "    note = 'finecutmix',\n",
        "    backbone='swin_base_patch4_window12_384',\n",
        "    embedder= None,\n",
        "    train_batch_size=8,\n",
        "    valid_batch_size=16,\n",
        "    img_size=384,\n",
        "    num_epochs=50,\n",
        "    early_stopping = False,\n",
        "    early_stopping_step = 5,\n",
        "    learning_rate=1e-4,\n",
        "    scheduler='CosineAnnealingLR',\n",
        "    min_lr=1e-6,\n",
        "    T_max=100,\n",
        "    num_classes = 25,\n",
        "    weight_decay=1e-6,\n",
        "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "    competition='lg',\n",
        "    _wandb_kernel='deb'\n",
        ")\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx29VXnL7Hz7"
      },
      "source": [
        "# SET SEED "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:25:17.896790Z",
          "iopub.status.busy": "2022-01-15T10:25:17.896189Z",
          "iopub.status.idle": "2022-01-15T10:25:17.909599Z",
          "shell.execute_reply": "2022-01-15T10:25:17.908786Z",
          "shell.execute_reply.started": "2022-01-15T10:25:17.896748Z"
        },
        "id": "5h6rMiPw7Hz7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "\n",
        "set_seed(CONFIG['seed'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6-fw8V27Hz8"
      },
      "source": [
        "# Read the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "a581b2e779114786a321d4bd1439eebf"
          ]
        },
        "execution": {
          "iopub.execute_input": "2022-01-15T10:25:17.911360Z",
          "iopub.status.busy": "2022-01-15T10:25:17.910859Z",
          "iopub.status.idle": "2022-01-15T10:28:30.802857Z",
          "shell.execute_reply": "2022-01-15T10:28:30.801968Z",
          "shell.execute_reply.started": "2022-01-15T10:25:17.911319Z"
        },
        "id": "nCguZnEz7Hz9",
        "outputId": "e47ef21e-fb34-43e5-c504-d364c965a5b1",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:1ycjalgj) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 186... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a581b2e779114786a321d4bd1439eebf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.60MB of 0.60MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "</div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>0.83901</td></tr><tr><td>Train F1</td><td>0.80408</td></tr><tr><td>Train Loss</td><td>0.47385</td></tr><tr><td>Valid Accuracy</td><td>1</td></tr><tr><td>Valid F1</td><td>1</td></tr><tr><td>Valid Loss</td><td>0.0009</td></tr></table>\n",
              "</div></div>\n",
              "Synced 3 W&B file(s), 0 media file(s), 6 artifact file(s) and 2 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">SwinB finecutmix</strong>: <a href=\"https://wandb.ai/jiwon7258/lg/runs/1ycjalgj\" target=\"_blank\">https://wandb.ai/jiwon7258/lg/runs/1ycjalgj</a><br/>\n",
              "Find logs at: <code>./wandb/run-20220130_110528-1ycjalgj/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:1ycjalgj). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    Resuming run <strong><a href=\"https://wandb.ai/jiwon7258/lg/runs/1ycjalgj\" target=\"_blank\">SwinB finecutmix</a></strong> to <a href=\"https://wandb.ai/jiwon7258/lg\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact lg_train:v0, 918.24MB. 17301 files... Done. 0:0:0\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "run = wandb.init(project=\"lg\",\n",
        "                 entity=\"jiwon7258\",\n",
        "                 config=CONFIG,\n",
        "                 job_type='train',\n",
        "                #  id='2ow4king',\n",
        "                #  resume='must',\n",
        "                 )\n",
        "dataset = wandb.run.use_artifact(\n",
        "    'jiwon7258/lg/lg_train:v0', type='dataset')\n",
        "\n",
        "run.name = CONFIG['nickname']\n",
        "\n",
        "# Download the artifact's contents\n",
        "dataset_dir = dataset.download()\n",
        "dataset_dir = Path(dataset_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:28:30.804754Z",
          "iopub.status.busy": "2022-01-15T10:28:30.804383Z",
          "iopub.status.idle": "2022-01-15T10:28:30.809944Z",
          "shell.execute_reply": "2022-01-15T10:28:30.809259Z",
          "shell.execute_reply.started": "2022-01-15T10:28:30.804698Z"
        },
        "id": "jXvqo8Jg7Hz9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH = dataset_dir\n",
        "# TEST_PATH = dataset_dir / 'test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1DmqMbW7Hz-"
      },
      "source": [
        "# Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:28:30.813928Z",
          "iopub.status.busy": "2022-01-15T10:28:30.811190Z",
          "iopub.status.idle": "2022-01-15T10:28:30.822155Z",
          "shell.execute_reply": "2022-01-15T10:28:30.821435Z",
          "shell.execute_reply.started": "2022-01-15T10:28:30.813872Z"
        },
        "id": "_qhXSwA-7Hz-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "    \"train\": A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.15,\n",
        "                           rotate_limit=35, p=0.5),\n",
        "        A.RGBShift(r_shift_limit=15, g_shift_limit=15,\n",
        "                   b_shift_limit=15, p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.5),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.Normalize(),\n",
        "        ToTensorV2()], p=1.),\n",
        "\n",
        "    \"valid\": A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.Normalize(),\n",
        "        ToTensorV2()], p=1.)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azbb7YtN7Hz_"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:28:30.825534Z",
          "iopub.status.busy": "2022-01-15T10:28:30.824486Z",
          "iopub.status.idle": "2022-01-15T10:28:31.525603Z",
          "shell.execute_reply": "2022-01-15T10:28:31.524866Z",
          "shell.execute_reply.started": "2022-01-15T10:28:30.825498Z"
        },
        "id": "npQ2IU4d7Hz_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_csv = sorted(glob(str(TRAIN_PATH / '*/*.csv')))\n",
        "train_jpg = sorted(glob(str(TRAIN_PATH / '*/*.jpg')))\n",
        "train_json = sorted(glob(str(TRAIN_PATH / '*/*.json')))\n",
        "\n",
        "\n",
        "crops = []\n",
        "diseases = []\n",
        "risks = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(train_json)):\n",
        "    with open(train_json[i], 'r') as f:\n",
        "        sample = json.load(f)\n",
        "        crop = sample['annotations']['crop']\n",
        "        disease = sample['annotations']['disease']\n",
        "        risk = sample['annotations']['risk']\n",
        "        label=f\"{crop}_{disease}_{risk}\"\n",
        "    \n",
        "        crops.append(crop)\n",
        "        diseases.append(disease)\n",
        "        risks.append(risk)\n",
        "        labels.append(label)\n",
        "        \n",
        "label_unique = sorted(np.unique(labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
        "\n",
        "train_labels = [label_unique[k] for k in labels] # len = train_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrOP6YmU7H0A"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(label_unique, 'label_unique')\n",
        "wandb.save('label_unique')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:28:31.539757Z",
          "iopub.status.busy": "2022-01-15T10:28:31.539171Z",
          "iopub.status.idle": "2022-01-15T10:28:31.561040Z",
          "shell.execute_reply": "2022-01-15T10:28:31.560138Z",
          "shell.execute_reply.started": "2022-01-15T10:28:31.539702Z"
        },
        "id": "g9kC6HIt7H0A",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_jpg = np.array(train_jpg)\n",
        "train_labels = np.array(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:28:31.562715Z",
          "iopub.status.busy": "2022-01-15T10:28:31.562438Z",
          "iopub.status.idle": "2022-01-15T10:28:31.587681Z",
          "shell.execute_reply": "2022-01-15T10:28:31.586382Z",
          "shell.execute_reply.started": "2022-01-15T10:28:31.562681Z"
        },
        "id": "_LBbc5yi7H0B",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, train_img, train_label, transforms=None):\n",
        "        self.imgs = train_img\n",
        "        self.labels = train_label\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.imgs[index]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        target = self.labels[index]\n",
        "        \n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)[\"image\"]\n",
        "            \n",
        "        return img, target\n",
        "    \n",
        "# trainDataset = CustomDataset(X_train, y_train, transforms = data_transforms['train'])\n",
        "# trainDataloader = DataLoader(\n",
        "#     trainDataset, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
        "\n",
        "# validDataset = CustomDataset(X_val, y_val, transforms = data_transforms['valid'])\n",
        "# validDataloader = DataLoader(validDataset, batch_size = CONFIG['valid_batch_size'], shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zybX-c-3tTAX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "train_datasets = []\n",
        "valid_datasets = []\n",
        "train_dataloaders = []\n",
        "valid_dataloaders = []\n",
        "\n",
        "skf = StratifiedKFold(n_splits = 5)\n",
        "\n",
        "for step, (train_index, val_index) in enumerate(skf.split(X = train_jpg, y= train_labels)):\n",
        "    X_train = train_jpg[train_index]\n",
        "    y_train = train_labels[train_index]\n",
        "    X_val = train_jpg[val_index]\n",
        "    y_val = train_labels[val_index]\n",
        "    train_datasets.append(CustomDataset(\n",
        "        X_train, y_train, transforms=data_transforms['train']))\n",
        "    valid_datasets.append(CustomDataset(\n",
        "        X_val, y_val, transforms=data_transforms['valid']))\n",
        "    train_dataloaders.append(DataLoader(\n",
        "        train_datasets[step], batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
        "    )\n",
        "    valid_dataloaders.append(\n",
        "        DataLoader(\n",
        "            valid_datasets[step], batch_size=CONFIG['valid_batch_size'], shuffle=True)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1m8WStFtTpz"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "execution": {
          "iopub.execute_input": "2022-01-15T10:28:31.595710Z",
          "iopub.status.busy": "2022-01-15T10:28:31.592703Z",
          "iopub.status.idle": "2022-01-15T10:29:04.375344Z",
          "shell.execute_reply": "2022-01-15T10:29:04.374595Z",
          "shell.execute_reply.started": "2022-01-15T10:28:31.595662Z"
        },
        "id": "2quioTyF7H0B",
        "outputId": "33548121-0359-43b5-c043-d6179f7eae9a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22kto1k.pth\" to /root/.cache/torch/hub/checkpoints/swin_base_patch4_window12_384_22kto1k.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, backbone, embedder, pretrained=True):\n",
        "        super(Model, self).__init__()\n",
        "        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n",
        "        self.n_features = self.backbone.head.in_features\n",
        "        self.backbone.reset_classifier(0)\n",
        "        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n",
        "\n",
        "    def forward(self, images):\n",
        "        # features = (bs, embedding_size)\n",
        "        features = self.backbone(images)\n",
        "        # outputs  = (bs, num_classes)\n",
        "        output = self.fc(features)\n",
        "        return output\n",
        "\n",
        "\n",
        "model = Model(CONFIG['backbone'], CONFIG['embedder'], pretrained = True)\n",
        "model.to(CONFIG['device'])\n",
        ";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:29:04.376696Z",
          "iopub.status.busy": "2022-01-15T10:29:04.376445Z",
          "iopub.status.idle": "2022-01-15T10:29:04.383964Z",
          "shell.execute_reply": "2022-01-15T10:29:04.383287Z",
          "shell.execute_reply.started": "2022-01-15T10:29:04.376660Z"
        },
        "id": "zaYappsy7H0C",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "    params=model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:29:04.385682Z",
          "iopub.status.busy": "2022-01-15T10:29:04.385257Z",
          "iopub.status.idle": "2022-01-15T10:29:05.537793Z",
          "shell.execute_reply": "2022-01-15T10:29:05.536741Z",
          "shell.execute_reply.started": "2022-01-15T10:29:04.385649Z"
        },
        "id": "pRsRgVgk7H0C",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def criterion(logits: torch.tensor, targets: torch.tensor):\n",
        "    return nn.CrossEntropyLoss()(logits.view(-1,CONFIG['num_classes']), targets.view(-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPYus03_UfvH"
      },
      "source": [
        "# CutMix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "l8XzN0C2UfvH"
      },
      "outputs": [],
      "source": [
        "def cutmix(img, target):\n",
        "    \"\"\" \n",
        "    img : (bs, C, H, W)\n",
        "    target\n",
        "        - (bs,)\n",
        "        - integer scalar\n",
        "    \"\"\"\n",
        "    batch_size, C, H, W, = img.shape\n",
        "    # ic(img.shape)\n",
        "\n",
        "    img_a = img\n",
        "    target_a = target\n",
        "    img_b = img\n",
        "    target_b = target\n",
        "\n",
        "    mask = np.arange(batch_size)\n",
        "    mask = np.random.permutation(mask)\n",
        "    # ic(mask)\n",
        "    img_b = img_a[mask]\n",
        "    target_b = target_a[mask]\n",
        "    # ic(target, target_b)\n",
        "\n",
        "    lam = np.random.uniform(low=0.3, high=0.7)\n",
        "    r_x = np.random.uniform(low=0, high=W)\n",
        "    r_y = np.random.uniform(low=0, high=H)\n",
        "    r_w = W * np.sqrt(1 - lam)\n",
        "    r_h = H * np.sqrt(1 - lam)\n",
        "    ic(lam, r_x, r_y, r_w, r_h)\n",
        "    x1 = np.int(np.clip((r_x - r_w) / 2, 0, W))\n",
        "    x2 = np.int(np.clip((r_x + r_w) / 2, 0, W))\n",
        "    y1 = np.int(np.clip((r_y - r_h) / 2, 0, H))\n",
        "    y2 = np.int(np.clip((r_y + r_h) / 2, 0, H))\n",
        "    ic(x1, x2, y1, y2)\n",
        "\n",
        "    img_a[:, :, y1:y2, x1:x2] = img_b[:, :, y1:y2, x1:x2]\n",
        "\n",
        "    # Adjust lambda to exact ratio\n",
        "\n",
        "    lam = 1 - (x2 - x1) * (y2 - y1) / float(W * H)\n",
        "\n",
        "    return img_a, target_b, lam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTfsj-Y17H0C"
      },
      "source": [
        "   # Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:33:47.356814Z",
          "iopub.status.busy": "2022-01-15T10:33:47.356540Z",
          "iopub.status.idle": "2022-01-15T10:33:47.375626Z",
          "shell.execute_reply": "2022-01-15T10:33:47.373734Z",
          "shell.execute_reply.started": "2022-01-15T10:33:47.356781Z"
        },
        "id": "iCswmFhy7H0D",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
        "    # train 모드로 변경\n",
        "    model.train()\n",
        "\n",
        "    # for the Mixed Precision\n",
        "    # Pytorch 예제 : https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples\n",
        "    if(FP16):\n",
        "        scaler = amp.GradScaler()\n",
        "\n",
        "    losses = AverageMeter()\n",
        "    accuracy = AverageMeter()\n",
        "    f1 = AverageMeter()\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "\n",
        "    for step, (img, target) in bar:\n",
        "        img, target_b, lam = cutmix(img, target)\n",
        "\n",
        "        img = img.to(device)\n",
        "        target = target.to(device)\n",
        "        target_b = target_b.to(device)\n",
        "\n",
        "        batch_size = img.shape[0]\n",
        "\n",
        "        if(FP16):\n",
        "            with amp.autocast(enabled=True):\n",
        "                logits = model(img)\n",
        "                loss = criterion(logits, target) * lam + \\\n",
        "                    criterion(logits, target_b) * (1-lam)\n",
        "\n",
        "                # loss를 Scale\n",
        "                # Scaled Grdients를 계산(call)하기 위해 scaled loss를 backward()\n",
        "                scaler.scale(loss).backward()\n",
        "                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "                # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
        "                # otherwise, optimizer.step() is skipped.\n",
        "                scaler.step(optimizer)\n",
        "\n",
        "                # Updates the scale for next iteration.\n",
        "                scaler.update()\n",
        "\n",
        "        else:\n",
        "            logits = model(img)\n",
        "            loss = criterion(logits, target) * lam + \\\n",
        "                criterion(logits, target_b) * (1-lam)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "            optimizer.step()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # change learning rate by Scheduler\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        # loss.item()은 loss를 Python Float으로 반환\n",
        "        losses.update(loss.item())\n",
        "\n",
        "        # logits\n",
        "        logits = logits.detach().cpu()\n",
        "\n",
        "        # acc, f1\n",
        "        probs = torch.softmax(logits, dim = -1)\n",
        "        output = np.argmax(probs, axis=-1)\n",
        "        output_b = np.argsort(probs)[:,-2]\n",
        "        if (lam >= 0.5):\n",
        "            step_acc = np.mean(\n",
        "                output.view(-1).numpy() == target.view(-1).detach().cpu().numpy())\n",
        "            step_f1 = f1_score(output.view(-1).numpy(),\n",
        "                               target.view(-1).detach().cpu().numpy(), average='macro')\n",
        "            step_acc_b = np.mean(\n",
        "                output_b.view(-1).numpy() == target_b.view(-1).detach().cpu().numpy())\n",
        "            step_f1_b = f1_score(output_b.view(-1).numpy(),\n",
        "                                 target_b.view(-1).detach().cpu().numpy(), average='macro')\n",
        "        else:\n",
        "            step_acc = np.mean(\n",
        "                output.view(-1).numpy() == target_b.view(-1).detach().cpu().numpy())\n",
        "            step_f1 = f1_score(output.view(-1).numpy(),\n",
        "                               target_b.view(-1).detach().cpu().numpy(), average='macro')\n",
        "            step_acc_b = np.mean(\n",
        "                output_b.view(-1).numpy() == target.view(-1).detach().cpu().numpy())\n",
        "            step_f1_b = f1_score(output_b.view(-1).numpy(),\n",
        "                                 target.view(-1).detach().cpu().numpy(), average='macro')\n",
        "\n",
        "                                 \n",
        "        step_acc = step_acc * lam + step_acc_b * (1-lam)\n",
        "        step_f1 = step_f1 * lam + step_f1_b * (1-lam)\n",
        "\n",
        "        accuracy.update(step_acc)\n",
        "        f1.update(step_f1)\n",
        "\n",
        "        # loss\n",
        "        train_loss = losses.avg\n",
        "        train_acc = accuracy.avg\n",
        "        train_f1 = f1.avg\n",
        "\n",
        "        bar.set_postfix(\n",
        "            Epoch=epoch, Train_Loss=train_loss, LR=optimizer.param_groups[\n",
        "                0][\"lr\"], accuracy=train_acc, f1=train_f1\n",
        "        )\n",
        "\n",
        "    # Garbage Collector\n",
        "    gc.collect()\n",
        "\n",
        "    return losses.avg, accuracy.avg, f1.avg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5PB19nv7H0D"
      },
      "source": [
        "   # Validation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:33:47.378229Z",
          "iopub.status.busy": "2022-01-15T10:33:47.377682Z",
          "iopub.status.idle": "2022-01-15T10:33:47.393570Z",
          "shell.execute_reply": "2022-01-15T10:33:47.392783Z",
          "shell.execute_reply.started": "2022-01-15T10:33:47.378191Z"
        },
        "id": "aJRJrmiG7H0E",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model, dataloader, device, epoch):\n",
        "    model.eval()\n",
        "\n",
        "    losses = AverageMeter()\n",
        "    accuracy = AverageMeter()\n",
        "    f1 = AverageMeter()\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "\n",
        "    for step, (img, target) in bar:\n",
        "        img = img.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        batch_size = img.shape[0]\n",
        "\n",
        "        logits = model(img)\n",
        "        loss = criterion(logits, target)\n",
        "\n",
        "        # loss.item()은 loss를 Python Float으로 반환\n",
        "        losses.update(loss.item())\n",
        "\n",
        "        # logits\n",
        "        logits = logits.detach().cpu()\n",
        "\n",
        "        output = np.argmax(torch.softmax(logits, dim=-1), axis=-1)\n",
        "        step_acc = np.mean(\n",
        "            output.view(-1).numpy() == target.view(-1).detach().cpu().numpy())\n",
        "        step_f1 = f1_score(output.view(-1).numpy(),\n",
        "                           target.view(-1).detach().cpu().numpy(), average='macro')\n",
        "\n",
        "        accuracy.update(step_acc)\n",
        "        f1.update(step_f1)\n",
        "\n",
        "        # loss\n",
        "        val_loss = losses.avg\n",
        "        val_acc = accuracy.avg\n",
        "        val_f1 = f1.avg\n",
        "\n",
        "        bar.set_postfix(\n",
        "            Epoch=epoch, Valid_Loss=val_loss, LR=optimizer.param_groups[\n",
        "                0][\"lr\"], accuracy=val_acc, f1=val_f1\n",
        "        )\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    return losses.avg, accuracy.avg, f1.avg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:33:47.395930Z",
          "iopub.status.busy": "2022-01-15T10:33:47.395337Z",
          "iopub.status.idle": "2022-01-15T10:33:47.415192Z",
          "shell.execute_reply": "2022-01-15T10:33:47.414280Z",
          "shell.execute_reply.started": "2022-01-15T10:33:47.395894Z"
        },
        "id": "kZfD8q3s7H0E",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_training(\n",
        "    model,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    device,\n",
        "    num_epochs,\n",
        "    metric_prefix=\"\",\n",
        "    file_prefix=\"\",\n",
        "    early_stopping=True,\n",
        "    early_stopping_step=10,\n",
        "    START_EPOCH = 0,\n",
        "):\n",
        "    # To automatically log graidents\n",
        "    wandb.watch(model, log_freq=100)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU:{}\\n\".format(torch.cuda.get_device_name()))\n",
        "\n",
        "    start = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = np.inf\n",
        "    history = defaultdict(list)\n",
        "    early_stop_counter = 0\n",
        "\n",
        "    # num_epochs만큼, train과 val을 실행한다\n",
        "    for epoch in range(START_EPOCH, START_EPOCH + num_epochs):\n",
        "        gc.collect()\n",
        "\n",
        "        fold_num = 5\n",
        "        fold = epoch % fold_num\n",
        "\n",
        "        # for fold in range(fold_num) :\n",
        "\n",
        "        trainDataloader = train_dataloaders[fold]\n",
        "        validDataloader = valid_dataloaders[fold]\n",
        "\n",
        "        train_train_loss, train_accuracy, train_f1 = train_one_epoch(\n",
        "            model,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            dataloader=trainDataloader,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "        )\n",
        "\n",
        "        val_loss, val_accuracy, val_f1 = valid_one_epoch(\n",
        "            model, validDataloader, device=device, epoch=epoch\n",
        "        )\n",
        "\n",
        "\n",
        "        history[f\"{metric_prefix}Train Loss\"].append(train_train_loss)\n",
        "        history[f\"{metric_prefix}Train Accuracy\"].append(train_accuracy)\n",
        "        history[f\"{metric_prefix}Train F1\"].append(train_f1)\n",
        "        history[f\"{metric_prefix}Valid Loss\"].append(val_loss)\n",
        "        history[f\"{metric_prefix}Valid Accuracy\"].append(val_accuracy)\n",
        "        history[f\"{metric_prefix}Valid F1\"].append(val_f1)\n",
        "\n",
        "        # Log the metrics\n",
        "        wandb.log(\n",
        "            {\n",
        "                f\"{metric_prefix}Train Loss\": train_train_loss,\n",
        "                f\"{metric_prefix}Valid Loss\": val_loss,\n",
        "                f\"{metric_prefix}Train Accuracy\": train_accuracy,\n",
        "                f\"{metric_prefix}Valid Accuracy\": val_accuracy,\n",
        "                f\"{metric_prefix}Train F1\": train_f1,\n",
        "                f\"{metric_prefix}Valid F1\": val_f1,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        print(f\"Valid Loss : {val_loss}\")\n",
        "\n",
        "        torch.save(model.state_dict(), f'last.bin')\n",
        "        wandb.save(f'last.bin')\n",
        "\n",
        "        # deep copy the model\n",
        "        if val_loss <= best_loss:\n",
        "            early_stop_counter = 0\n",
        "\n",
        "            print(\n",
        "                f\"Validation Loss improved( {best_loss} ---> {val_loss}  )\"\n",
        "            )\n",
        "\n",
        "            # Update Best Loss\n",
        "            best_loss = val_loss\n",
        "\n",
        "            # Update Best Model Weight\n",
        "            # run.summary['Best RMSE'] = best_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            PATH = \"{}epoch{:.0f}_Loss{:.4f}.bin\".format(\n",
        "                file_prefix, epoch, best_loss)\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            # Save a model file from the current directory\n",
        "            wandb.save(PATH)\n",
        "\n",
        "            print(f\"Model Saved\")\n",
        "\n",
        "        elif early_stopping:\n",
        "            early_stop_counter += 1\n",
        "            if early_stop_counter > early_stopping_step:\n",
        "                break\n",
        "\n",
        "        START_EPOCH = epoch + 1\n",
        "        # break\n",
        "\n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "    print(\n",
        "        \"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n",
        "            time_elapsed // 3600,\n",
        "            (time_elapsed % 3600) // 60,\n",
        "            (time_elapsed % 3600) % 60,\n",
        "        )\n",
        "    )\n",
        "    print(\"Best Loss: {:.4f}\".format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZoQGp1g7H0F"
      },
      "source": [
        " # Run training 20 Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-01-15T10:33:47.416354Z",
          "iopub.status.busy": "2022-01-15T10:33:47.416056Z",
          "iopub.status.idle": "2022-01-15T10:33:48.692352Z",
          "shell.execute_reply": "2022-01-15T10:33:48.691550Z",
          "shell.execute_reply.started": "2022-01-15T10:33:47.416328Z"
        },
        "id": "5xm9Mgvi7H0F",
        "outputId": "a68305e5-f313-4a46-c48b-97ee401993c8",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.restore('final.bin', 'jiwon7258/lg/1ycjalgj', root='./')\n",
        "model.load_state_dict(torch.load('final.bin',\n",
        "                      map_location=CONFIG['device']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KOqbWjut1_U"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "    params=model.parameters(), lr=1e-6, weight_decay=CONFIG['weight_decay'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-15T10:33:48.694521Z",
          "iopub.status.busy": "2022-01-15T10:33:48.694198Z"
        },
        "id": "AEfH7v4s7H0F",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "ic.disable()\n",
        "run_training(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    # scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    #     optimizer=optimizer, T_max=CONFIG['T_max'], eta_min=CONFIG['min_lr']),\n",
        "    scheduler = None,\n",
        "    device=device,\n",
        "    num_epochs=20,\n",
        "    metric_prefix=\"\",\n",
        "    file_prefix=\"\",\n",
        "    early_stopping=CONFIG['early_stopping'],\n",
        "    early_stopping_step=CONFIG['early_stopping_step'],\n",
        "    START_EPOCH=0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmdaOtBp7H0F",
        "outputId": "735866ca-fc9d-4205-9d21-995f0300b366",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/wandb/run-20220126_074607-1ycjalgj/files/final.bin']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.save(model.state_dict(), 'final.bin')\n",
        "wandb.save('final.bin')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3WWGqnnB98J"
      },
      "source": [
        "# 60 epoch (~80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_RAJN7SAxu7",
        "outputId": "c895520d-b512-4c1a-96a5-c00f8001a92e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('last.bin',\n",
        "                      map_location=CONFIG['device']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrnHEPu2CPso"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "    params=model.parameters(), lr=1e-6, weight_decay=CONFIG['weight_decay'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36gEoMBp-SO8",
        "outputId": "e0c10063-5bc8-48d4-b545-d0f92e59d794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Using GPU:Tesla P100-PCIE-16GB\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=20, LR=1e-6, Train_Loss=0.569, accuracy=0.784, f1=0.733]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=20, LR=1e-6, Valid_Loss=0.00395, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.003950121209714307\n",
            "Validation Loss improved( inf ---> 0.003950121209714307  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=21, LR=1e-6, Train_Loss=0.559, accuracy=0.794, f1=0.745]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=21, LR=1e-6, Valid_Loss=0.00443, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.004431140178508342\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:06<00:00,  1.19it/s, Epoch=22, LR=1e-6, Train_Loss=0.535, accuracy=0.791, f1=0.744]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=22, LR=1e-6, Valid_Loss=0.00422, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.004221856592490963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:06<00:00,  1.19it/s, Epoch=23, LR=1e-6, Train_Loss=0.545, accuracy=0.796, f1=0.751]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=23, LR=1e-6, Valid_Loss=0.00383, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.003831881398258552\n",
            "Validation Loss improved( 0.003950121209714307 ---> 0.003831881398258552  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:04<00:00,  1.19it/s, Epoch=24, LR=1e-6, Train_Loss=0.55, accuracy=0.781, f1=0.73]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.75it/s, Epoch=24, LR=1e-6, Valid_Loss=0.00364, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0036377490399252268\n",
            "Validation Loss improved( 0.003831881398258552 ---> 0.0036377490399252268  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:03<00:00,  1.19it/s, Epoch=25, LR=1e-6, Train_Loss=0.538, accuracy=0.795, f1=0.744]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.75it/s, Epoch=25, LR=1e-6, Valid_Loss=0.00319, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.003189876463506626\n",
            "Validation Loss improved( 0.0036377490399252268 ---> 0.003189876463506626  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:03<00:00,  1.19it/s, Epoch=26, LR=1e-6, Train_Loss=0.539, accuracy=0.796, f1=0.747]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.75it/s, Epoch=26, LR=1e-6, Valid_Loss=0.00363, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0036345131086083513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:04<00:00,  1.19it/s, Epoch=27, LR=1e-6, Train_Loss=0.533, accuracy=0.79, f1=0.743]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.75it/s, Epoch=27, LR=1e-6, Valid_Loss=0.00362, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0036215206579471083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:04<00:00,  1.19it/s, Epoch=28, LR=1e-6, Train_Loss=0.523, accuracy=0.805, f1=0.757]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=28, LR=1e-6, Valid_Loss=0.00286, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0028610042525991186\n",
            "Validation Loss improved( 0.003189876463506626 ---> 0.0028610042525991186  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:04<00:00,  1.19it/s, Epoch=29, LR=1e-6, Train_Loss=0.534, accuracy=0.79, f1=0.741]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=29, LR=1e-6, Valid_Loss=0.00294, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0029360233002329525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:05<00:00,  1.19it/s, Epoch=30, LR=1e-6, Train_Loss=0.53, accuracy=0.798, f1=0.748]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.75it/s, Epoch=30, LR=1e-6, Valid_Loss=0.00271, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.002711160148315336\n",
            "Validation Loss improved( 0.0028610042525991186 ---> 0.002711160148315336  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:05<00:00,  1.19it/s, Epoch=31, LR=1e-6, Train_Loss=0.52, accuracy=0.813, f1=0.768]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=31, LR=1e-6, Valid_Loss=0.00299, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.002990217281390645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:05<00:00,  1.19it/s, Epoch=32, LR=1e-6, Train_Loss=0.549, accuracy=0.789, f1=0.74]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.75it/s, Epoch=32, LR=1e-6, Valid_Loss=0.0033, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0033005270325540477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:05<00:00,  1.19it/s, Epoch=33, LR=1e-6, Train_Loss=0.515, accuracy=0.821, f1=0.777]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=33, LR=1e-6, Valid_Loss=0.00233, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.002327970345504582\n",
            "Validation Loss improved( 0.002711160148315336 ---> 0.002327970345504582  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:06<00:00,  1.19it/s, Epoch=34, LR=1e-6, Train_Loss=0.527, accuracy=0.797, f1=0.752]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=34, LR=1e-6, Valid_Loss=0.00264, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0026438598240381235\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:06<00:00,  1.19it/s, Epoch=35, LR=1e-6, Train_Loss=0.534, accuracy=0.798, f1=0.748]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=35, LR=1e-6, Valid_Loss=0.00244, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0024396029160651442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:06<00:00,  1.19it/s, Epoch=36, LR=1e-6, Train_Loss=0.514, accuracy=0.796, f1=0.75]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=36, LR=1e-6, Valid_Loss=0.00257, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0025689132481315877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:06<00:00,  1.19it/s, Epoch=37, LR=1e-6, Train_Loss=0.513, accuracy=0.812, f1=0.77]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=37, LR=1e-6, Valid_Loss=0.00249, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.002492640121227564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=38, LR=1e-6, Train_Loss=0.515, accuracy=0.796, f1=0.747]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=38, LR=1e-6, Valid_Loss=0.00235, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.00235338051235686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=39, LR=1e-6, Train_Loss=0.503, accuracy=0.811, f1=0.766]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=39, LR=1e-6, Valid_Loss=0.00223, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0022284537458103406\n",
            "Validation Loss improved( 0.002327970345504582 ---> 0.0022284537458103406  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=40, LR=1e-6, Train_Loss=0.52, accuracy=0.805, f1=0.76]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=40, LR=1e-6, Valid_Loss=0.00219, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.002188369394152438\n",
            "Validation Loss improved( 0.0022284537458103406 ---> 0.002188369394152438  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=41, LR=1e-6, Train_Loss=0.511, accuracy=0.812, f1=0.767]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=41, LR=1e-6, Valid_Loss=0.00219, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0021910975609064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=42, LR=1e-6, Train_Loss=0.522, accuracy=0.813, f1=0.768]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=42, LR=1e-6, Valid_Loss=0.00221, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.00220629422325794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:06<00:00,  1.19it/s, Epoch=43, LR=1e-6, Train_Loss=0.518, accuracy=0.81, f1=0.765]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=43, LR=1e-6, Valid_Loss=0.00184, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0018448205888016175\n",
            "Validation Loss improved( 0.002188369394152438 ---> 0.0018448205888016175  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=44, LR=1e-6, Train_Loss=0.502, accuracy=0.822, f1=0.78]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=44, LR=1e-6, Valid_Loss=0.00202, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0020200101138819777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=45, LR=1e-6, Train_Loss=0.498, accuracy=0.806, f1=0.763]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=45, LR=1e-6, Valid_Loss=0.00175, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0017517801654869563\n",
            "Validation Loss improved( 0.0018448205888016175 ---> 0.0017517801654869563  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=46, LR=1e-6, Train_Loss=0.498, accuracy=0.82, f1=0.778]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=46, LR=1e-6, Valid_Loss=0.00184, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0018446449707070851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=47, LR=1e-6, Train_Loss=0.519, accuracy=0.811, f1=0.769]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=47, LR=1e-6, Valid_Loss=0.00193, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.001928642584323526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=48, LR=1e-6, Train_Loss=0.501, accuracy=0.822, f1=0.78]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=48, LR=1e-6, Valid_Loss=0.0016, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0015954918647503914\n",
            "Validation Loss improved( 0.0017517801654869563 ---> 0.0015954918647503914  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=49, LR=1e-6, Train_Loss=0.501, accuracy=0.824, f1=0.782]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=49, LR=1e-6, Valid_Loss=0.00164, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0016388061196441215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:06<00:00,  1.19it/s, Epoch=50, LR=1e-6, Train_Loss=0.499, accuracy=0.821, f1=0.781]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=50, LR=1e-6, Valid_Loss=0.00146, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0014616903340227084\n",
            "Validation Loss improved( 0.0015954918647503914 ---> 0.0014616903340227084  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=51, LR=1e-6, Train_Loss=0.495, accuracy=0.816, f1=0.775]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=51, LR=1e-6, Valid_Loss=0.0016, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0015984887061066518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=52, LR=1e-6, Train_Loss=0.496, accuracy=0.823, f1=0.781]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=52, LR=1e-6, Valid_Loss=0.00169, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.001690683518026075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=53, LR=1e-6, Train_Loss=0.509, accuracy=0.815, f1=0.771]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=53, LR=1e-6, Valid_Loss=0.00153, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.001530912153786431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=54, LR=1e-6, Train_Loss=0.499, accuracy=0.814, f1=0.77]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=54, LR=1e-6, Valid_Loss=0.00162, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.001619412808532329\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=55, LR=1e-6, Train_Loss=0.498, accuracy=0.821, f1=0.778]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=55, LR=1e-6, Valid_Loss=0.00143, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0014282031876213645\n",
            "Validation Loss improved( 0.0014616903340227084 ---> 0.0014282031876213645  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:08<00:00,  1.18it/s, Epoch=56, LR=1e-6, Train_Loss=0.496, accuracy=0.817, f1=0.774]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=56, LR=1e-6, Valid_Loss=0.00154, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0015350532995485893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:08<00:00,  1.18it/s, Epoch=57, LR=1e-6, Train_Loss=0.493, accuracy=0.829, f1=0.788]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=57, LR=1e-6, Valid_Loss=0.00166, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.00165632112056961\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=58, LR=1e-6, Train_Loss=0.495, accuracy=0.827, f1=0.789]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=58, LR=1e-6, Valid_Loss=0.00121, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.001206072124697217\n",
            "Validation Loss improved( 0.0014282031876213645 ---> 0.001206072124697217  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=59, LR=1e-6, Train_Loss=0.487, accuracy=0.832, f1=0.79]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=59, LR=1e-6, Valid_Loss=0.00133, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0013301141770582085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=60, LR=1e-6, Train_Loss=0.493, accuracy=0.829, f1=0.787]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=60, LR=1e-6, Valid_Loss=0.00128, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0012840887193555292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=61, LR=1e-6, Train_Loss=0.488, accuracy=0.817, f1=0.773]\n",
            "100%|██████████| 73/73 [00:41<00:00,  1.74it/s, Epoch=61, LR=1e-6, Valid_Loss=0.00137, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0013734276927943813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=62, LR=1e-6, Train_Loss=0.496, accuracy=0.832, f1=0.789]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=62, LR=1e-6, Valid_Loss=0.00134, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0013363053838798954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=63, LR=1e-6, Train_Loss=0.482, accuracy=0.833, f1=0.793]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=63, LR=1e-6, Valid_Loss=0.0012, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0012012404494931642\n",
            "Validation Loss improved( 0.001206072124697217 ---> 0.0012012404494931642  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:08<00:00,  1.18it/s, Epoch=64, LR=1e-6, Train_Loss=0.494, accuracy=0.83, f1=0.789]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=64, LR=1e-6, Valid_Loss=0.00119, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0011939313749093818\n",
            "Validation Loss improved( 0.0012012404494931642 ---> 0.0011939313749093818  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:08<00:00,  1.18it/s, Epoch=65, LR=1e-6, Train_Loss=0.484, accuracy=0.823, f1=0.783]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=65, LR=1e-6, Valid_Loss=0.00108, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0010752349107985525\n",
            "Validation Loss improved( 0.0011939313749093818 ---> 0.0010752349107985525  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:08<00:00,  1.18it/s, Epoch=66, LR=1e-6, Train_Loss=0.485, accuracy=0.828, f1=0.789]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=66, LR=1e-6, Valid_Loss=0.00112, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0011184276759382081\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=67, LR=1e-6, Train_Loss=0.49, accuracy=0.824, f1=0.783]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=67, LR=1e-6, Valid_Loss=0.00111, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0011143204492950582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=68, LR=1e-6, Train_Loss=0.498, accuracy=0.826, f1=0.788]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=68, LR=1e-6, Valid_Loss=0.000987, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0009869184952599238\n",
            "Validation Loss improved( 0.0010752349107985525 ---> 0.0009869184952599238  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=69, LR=1e-6, Train_Loss=0.468, accuracy=0.831, f1=0.792]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=69, LR=1e-6, Valid_Loss=0.00109, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0010945847041088424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=70, LR=1e-6, Train_Loss=0.484, accuracy=0.823, f1=0.784]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=70, LR=1e-6, Valid_Loss=0.000995, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0009952296442288446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=71, LR=1e-6, Train_Loss=0.49, accuracy=0.818, f1=0.779]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=71, LR=1e-6, Valid_Loss=0.00111, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0011088984495360558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=72, LR=1e-6, Train_Loss=0.477, accuracy=0.834, f1=0.795]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=72, LR=1e-6, Valid_Loss=0.00102, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.00102223617531844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=73, LR=1e-6, Train_Loss=0.474, accuracy=0.843, f1=0.806]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=73, LR=1e-6, Valid_Loss=0.000898, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0008982392841286652\n",
            "Validation Loss improved( 0.0009869184952599238 ---> 0.0008982392841286652  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=74, LR=1e-6, Train_Loss=0.476, accuracy=0.837, f1=0.797]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=74, LR=1e-6, Valid_Loss=0.000926, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0009263351496647125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:06<00:00,  1.19it/s, Epoch=75, LR=1e-6, Train_Loss=0.482, accuracy=0.826, f1=0.785]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.74it/s, Epoch=75, LR=1e-6, Valid_Loss=0.00086, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0008601167674610161\n",
            "Validation Loss improved( 0.0008982392841286652 ---> 0.0008601167674610161  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=76, LR=1e-6, Train_Loss=0.47, accuracy=0.841, f1=0.804]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=76, LR=1e-6, Valid_Loss=0.00105, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.001046645647227407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=77, LR=1e-6, Train_Loss=0.484, accuracy=0.834, f1=0.795]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=77, LR=1e-6, Valid_Loss=0.000937, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0009367558084530373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=78, LR=1e-6, Train_Loss=0.474, accuracy=0.845, f1=0.811]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=78, LR=1e-6, Valid_Loss=0.000796, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.0007955803199390536\n",
            "Validation Loss improved( 0.0008601167674610161 ---> 0.0007955803199390536  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [08:07<00:00,  1.18it/s, Epoch=79, LR=1e-6, Train_Loss=0.474, accuracy=0.839, f1=0.804]\n",
            "100%|██████████| 73/73 [00:42<00:00,  1.73it/s, Epoch=79, LR=1e-6, Valid_Loss=0.000898, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.000898455188702154\n",
            "Training complete in 8h 51m 26s\n",
            "Best Loss: 0.0008\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(Model(\n",
              "   (backbone): SwinTransformer(\n",
              "     (patch_embed): PatchEmbed(\n",
              "       (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
              "       (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "     )\n",
              "     (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "     (layers): Sequential(\n",
              "       (0): BasicLayer(\n",
              "         dim=128, input_resolution=(96, 96), depth=2\n",
              "         (blocks): ModuleList(\n",
              "           (0): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): Identity()\n",
              "             (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (1): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "         )\n",
              "         (downsample): PatchMerging(\n",
              "           input_resolution=(96, 96), dim=128\n",
              "           (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
              "           (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "         )\n",
              "       )\n",
              "       (1): BasicLayer(\n",
              "         dim=256, input_resolution=(48, 48), depth=2\n",
              "         (blocks): ModuleList(\n",
              "           (0): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (1): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "         )\n",
              "         (downsample): PatchMerging(\n",
              "           input_resolution=(48, 48), dim=256\n",
              "           (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
              "           (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "         )\n",
              "       )\n",
              "       (2): BasicLayer(\n",
              "         dim=512, input_resolution=(24, 24), depth=18\n",
              "         (blocks): ModuleList(\n",
              "           (0): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (1): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (2): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (3): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (4): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (5): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (6): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (7): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (8): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (9): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (10): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (11): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (12): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (13): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (14): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (15): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (16): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (17): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "         )\n",
              "         (downsample): PatchMerging(\n",
              "           input_resolution=(24, 24), dim=512\n",
              "           (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "           (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "         )\n",
              "       )\n",
              "       (3): BasicLayer(\n",
              "         dim=1024, input_resolution=(12, 12), depth=2\n",
              "         (blocks): ModuleList(\n",
              "           (0): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "           (1): SwinTransformerBlock(\n",
              "             (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "             (attn): WindowAttention(\n",
              "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "               (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "               (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "               (softmax): Softmax(dim=-1)\n",
              "             )\n",
              "             (drop_path): DropPath()\n",
              "             (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "             (mlp): Mlp(\n",
              "               (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "               (act): GELU()\n",
              "               (drop1): Dropout(p=0.0, inplace=False)\n",
              "               (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "               (drop2): Dropout(p=0.0, inplace=False)\n",
              "             )\n",
              "           )\n",
              "         )\n",
              "       )\n",
              "     )\n",
              "     (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "     (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
              "     (head): Identity()\n",
              "   )\n",
              "   (fc): Linear(in_features=1024, out_features=25, bias=True)\n",
              " ),\n",
              " defaultdict(list,\n",
              "             {'Train Accuracy': [0.783885722947263,\n",
              "               0.7940673078848821,\n",
              "               0.7910392414016864,\n",
              "               0.7963110922971288,\n",
              "               0.781293340485013,\n",
              "               0.7948028282372681,\n",
              "               0.7955191727022478,\n",
              "               0.7898020576287524,\n",
              "               0.8052040691193308,\n",
              "               0.7896133232839041,\n",
              "               0.7977563007016093,\n",
              "               0.8129778495625491,\n",
              "               0.7885620946778251,\n",
              "               0.8213657692817958,\n",
              "               0.7967172332887078,\n",
              "               0.7977322900729119,\n",
              "               0.7964978913546472,\n",
              "               0.8121838965398509,\n",
              "               0.7956294385357994,\n",
              "               0.8110857691214816,\n",
              "               0.8046761844604895,\n",
              "               0.81184267381609,\n",
              "               0.8134148059817782,\n",
              "               0.8101647882224638,\n",
              "               0.821660337173263,\n",
              "               0.8055952516199875,\n",
              "               0.8198429603510549,\n",
              "               0.8113611442790697,\n",
              "               0.8217876161795324,\n",
              "               0.8239910043214093,\n",
              "               0.8213829447487146,\n",
              "               0.815794827413311,\n",
              "               0.8233237381319355,\n",
              "               0.8145405209655977,\n",
              "               0.813566829711515,\n",
              "               0.8206596843176626,\n",
              "               0.8165601304654965,\n",
              "               0.8293544711254927,\n",
              "               0.8270268147943171,\n",
              "               0.8318213738237558,\n",
              "               0.8287724712922027,\n",
              "               0.8166795042652442,\n",
              "               0.8322646583455747,\n",
              "               0.8329671605942264,\n",
              "               0.8297859778092949,\n",
              "               0.8227572985611834,\n",
              "               0.8283551794059838,\n",
              "               0.8242708055954225,\n",
              "               0.8258095754800566,\n",
              "               0.8306574374293862,\n",
              "               0.8230005215432352,\n",
              "               0.817717901737088,\n",
              "               0.8338779586830192,\n",
              "               0.8428864498959939,\n",
              "               0.8365906513933263,\n",
              "               0.826088836981386,\n",
              "               0.8407021648686857,\n",
              "               0.8337813946132419,\n",
              "               0.845303798014166,\n",
              "               0.8390095999262452],\n",
              "              'Train F1': [0.733034290775361,\n",
              "               0.7447589813842571,\n",
              "               0.7443824588296502,\n",
              "               0.7505985921233943,\n",
              "               0.7302636065288793,\n",
              "               0.7444054006443422,\n",
              "               0.7472030787857933,\n",
              "               0.743161848874712,\n",
              "               0.7565331684341746,\n",
              "               0.7409544033972307,\n",
              "               0.7478849081613842,\n",
              "               0.7675534817414683,\n",
              "               0.7402455941480348,\n",
              "               0.7765237961621316,\n",
              "               0.7515937761706937,\n",
              "               0.7481124354261541,\n",
              "               0.7500309483996765,\n",
              "               0.7700266654509622,\n",
              "               0.7474377107764163,\n",
              "               0.7664506708403558,\n",
              "               0.7597039929985094,\n",
              "               0.7672224107066656,\n",
              "               0.7682486626498587,\n",
              "               0.7653617476533133,\n",
              "               0.7799346919990596,\n",
              "               0.7625700798471241,\n",
              "               0.7780389938795594,\n",
              "               0.769087182841986,\n",
              "               0.7802203899108248,\n",
              "               0.7818749202113898,\n",
              "               0.780697157985825,\n",
              "               0.7754686381527034,\n",
              "               0.7810869056229977,\n",
              "               0.7708058308227322,\n",
              "               0.770208894824377,\n",
              "               0.7778364583386144,\n",
              "               0.7735025492168209,\n",
              "               0.7878729669732475,\n",
              "               0.7892553510541963,\n",
              "               0.7902903405961313,\n",
              "               0.7870303977356627,\n",
              "               0.7725697777732604,\n",
              "               0.788982946950081,\n",
              "               0.7928462385364994,\n",
              "               0.7891675035958496,\n",
              "               0.7833939769809304,\n",
              "               0.7889852564537565,\n",
              "               0.782754133293664,\n",
              "               0.7879756245806171,\n",
              "               0.7918508364999967,\n",
              "               0.7840839977071045,\n",
              "               0.7789920207308019,\n",
              "               0.7952803145868513,\n",
              "               0.8060841827090308,\n",
              "               0.7974663360597979,\n",
              "               0.7845483805890567,\n",
              "               0.8035049367441995,\n",
              "               0.7948228124605795,\n",
              "               0.8105284689561377,\n",
              "               0.8040769835443115],\n",
              "              'Train Loss': [0.5688855001021764,\n",
              "               0.5590195637067176,\n",
              "               0.5352026079192215,\n",
              "               0.5453022040888357,\n",
              "               0.5502060798757049,\n",
              "               0.5379171182435374,\n",
              "               0.5394328860711287,\n",
              "               0.5331069055292594,\n",
              "               0.5227163303256086,\n",
              "               0.5339638260959856,\n",
              "               0.529654675956244,\n",
              "               0.5195942367893116,\n",
              "               0.5486926058471926,\n",
              "               0.51468030344598,\n",
              "               0.526906996477957,\n",
              "               0.5340473410807408,\n",
              "               0.5139703668905761,\n",
              "               0.5133666197286735,\n",
              "               0.5150102689340501,\n",
              "               0.5026580944110154,\n",
              "               0.519552545305632,\n",
              "               0.510616974795376,\n",
              "               0.5222826149004739,\n",
              "               0.5181471942447811,\n",
              "               0.5017983586716254,\n",
              "               0.49786347683448107,\n",
              "               0.4980211056949671,\n",
              "               0.5188626777138593,\n",
              "               0.5014528911011987,\n",
              "               0.5010627809245353,\n",
              "               0.4987318725785179,\n",
              "               0.49492070682514683,\n",
              "               0.4962524436527227,\n",
              "               0.5085287086594611,\n",
              "               0.49948608820315327,\n",
              "               0.49759161815150565,\n",
              "               0.4956460654690371,\n",
              "               0.4929470158855155,\n",
              "               0.4950946492612672,\n",
              "               0.486790670748587,\n",
              "               0.4926895622254399,\n",
              "               0.4879298105491309,\n",
              "               0.49553602073499786,\n",
              "               0.4821244759171995,\n",
              "               0.4937358839325187,\n",
              "               0.4841509967916476,\n",
              "               0.48493973367590865,\n",
              "               0.48964097402324863,\n",
              "               0.49759854428349887,\n",
              "               0.4676047330157286,\n",
              "               0.48359563469441297,\n",
              "               0.49027546832864166,\n",
              "               0.47700810386755693,\n",
              "               0.4735523294346759,\n",
              "               0.47595090848721394,\n",
              "               0.48152653727377,\n",
              "               0.47025006855926776,\n",
              "               0.4836354462201489,\n",
              "               0.47392557960720266,\n",
              "               0.4738458023201577],\n",
              "              'Valid Accuracy': [1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0],\n",
              "              'Valid F1': [1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0,\n",
              "               1.0],\n",
              "              'Valid Loss': [0.003950121209714307,\n",
              "               0.004431140178508342,\n",
              "               0.004221856592490963,\n",
              "               0.003831881398258552,\n",
              "               0.0036377490399252268,\n",
              "               0.003189876463506626,\n",
              "               0.0036345131086083513,\n",
              "               0.0036215206579471083,\n",
              "               0.0028610042525991186,\n",
              "               0.0029360233002329525,\n",
              "               0.002711160148315336,\n",
              "               0.002990217281390645,\n",
              "               0.0033005270325540477,\n",
              "               0.002327970345504582,\n",
              "               0.0026438598240381235,\n",
              "               0.0024396029160651442,\n",
              "               0.0025689132481315877,\n",
              "               0.002492640121227564,\n",
              "               0.00235338051235686,\n",
              "               0.0022284537458103406,\n",
              "               0.002188369394152438,\n",
              "               0.0021910975609064,\n",
              "               0.00220629422325794,\n",
              "               0.0018448205888016175,\n",
              "               0.0020200101138819777,\n",
              "               0.0017517801654869563,\n",
              "               0.0018446449707070851,\n",
              "               0.001928642584323526,\n",
              "               0.0015954918647503914,\n",
              "               0.0016388061196441215,\n",
              "               0.0014616903340227084,\n",
              "               0.0015984887061066518,\n",
              "               0.001690683518026075,\n",
              "               0.001530912153786431,\n",
              "               0.001619412808532329,\n",
              "               0.0014282031876213645,\n",
              "               0.0015350532995485893,\n",
              "               0.00165632112056961,\n",
              "               0.001206072124697217,\n",
              "               0.0013301141770582085,\n",
              "               0.0012840887193555292,\n",
              "               0.0013734276927943813,\n",
              "               0.0013363053838798954,\n",
              "               0.0012012404494931642,\n",
              "               0.0011939313749093818,\n",
              "               0.0010752349107985525,\n",
              "               0.0011184276759382081,\n",
              "               0.0011143204492950582,\n",
              "               0.0009869184952599238,\n",
              "               0.0010945847041088424,\n",
              "               0.0009952296442288446,\n",
              "               0.0011088984495360558,\n",
              "               0.00102223617531844,\n",
              "               0.0008982392841286652,\n",
              "               0.0009263351496647125,\n",
              "               0.0008601167674610161,\n",
              "               0.001046645647227407,\n",
              "               0.0009367558084530373,\n",
              "               0.0007955803199390536,\n",
              "               0.000898455188702154]}))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ic.disable()\n",
        "run_training(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    # scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    #     optimizer=optimizer, T_max=CONFIG['T_max'], eta_min=CONFIG['min_lr']),\n",
        "    scheduler = None,\n",
        "    device=device,\n",
        "    num_epochs=60,\n",
        "    metric_prefix=\"\",\n",
        "    file_prefix=\"\",\n",
        "    early_stopping=CONFIG['early_stopping'],\n",
        "    early_stopping_step=CONFIG['early_stopping_step'],\n",
        "    START_EPOCH=20\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoxrKHuLqOMk"
      },
      "source": [
        "# 60 epoch (~ 140)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvopQ8TmrVcA",
        "outputId": "1b25ef30-c553-44a6-fe20-c43c1b45d32a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='./last.bin' mode='r' encoding='UTF-8'>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.restore('last.bin', 'jiwon7258/lg/1ycjalgj', root='./')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbmk0IsWqNGd",
        "outputId": "ce9ce7e4-da61-445b-bf3d-08f440cb8408"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('last.bin',\n",
        "                      map_location=CONFIG['device']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SC6_pRugqNGg"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "    params=model.parameters(), lr=1e-6, weight_decay=CONFIG['weight_decay'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmkhX3h7qg1g",
        "outputId": "b7a5c31d-9ba4-4cc6-9b8d-4119a6becefc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Using GPU:Tesla T4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 577/577 [12:05<00:00,  1.26s/it, Epoch=80, LR=1e-6, Train_Loss=0.541, accuracy=0.828, f1=0.786]\n",
            "100%|██████████| 73/73 [01:04<00:00,  1.13it/s, Epoch=80, LR=1e-6, Valid_Loss=0.000657, accuracy=1, f1=1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid Loss : 0.00065714538165955\n",
            "Validation Loss improved( inf ---> 0.00065714538165955  )\n",
            "Model Saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 19/577 [00:24<11:49,  1.27s/it, Epoch=81, LR=1e-6, Train_Loss=0.567, accuracy=0.853, f1=0.805]"
          ]
        }
      ],
      "source": [
        "ic.disable()\n",
        "run_training(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    # scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    #     optimizer=optimizer, T_max=CONFIG['T_max'], eta_min=CONFIG['min_lr']),\n",
        "    scheduler = None,\n",
        "    device=device,\n",
        "    num_epochs=100,\n",
        "    metric_prefix=\"\",\n",
        "    file_prefix=\"\",\n",
        "    early_stopping=CONFIG['early_stopping'],\n",
        "    early_stopping_step=CONFIG['early_stopping_step'],\n",
        "    START_EPOCH=80\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "lg_train_swinB_finecutmix.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
