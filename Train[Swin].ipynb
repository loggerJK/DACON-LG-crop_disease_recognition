{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "# from konlpy.tag import Mecab\n",
    "from nltk.tokenize import word_tokenize as en_tokenizer\n",
    "import sentencepiece as spm\n",
    "import urllib.request\n",
    "import csv\n",
    "import numpy as np\n",
    "from einops import rearrange, reduce, repeat\n",
    "from torch.cuda import amp\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import time\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import gc\n",
    "import os\n",
    "from icecream import ic\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "c_ = Fore.CYAN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ENV = 'COLAB'\n",
    "ENV = 'KAGGLE'\n",
    "# ENV = 'SYSTEM'\n",
    "\n",
    "# Option for Mixed Precision\n",
    "# FP16 = True\n",
    "FP16 = False\n",
    "\n",
    "N = 3\n",
    "HIDDEN_DIM = 128\n",
    "NUM_HEAD = 8\n",
    "INNER_DIM = 256\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "CONFIG = dict(\n",
    "    seed=42,\n",
    "    backbone='swin_base_patch4_window12_384',\n",
    "    embedder='tf_efficientnetv2_s',\n",
    "    train_batch_size=16,\n",
    "    valid_batch_size=32,\n",
    "    img_size=448,\n",
    "    epochs=5,\n",
    "    learning_rate=1e-4,\n",
    "    scheduler='CosineAnnealingLR',\n",
    "    min_lr=1e-6,\n",
    "    T_max=100,\n",
    "    num_classes = 10,\n",
    "    weight_decay=1e-6,\n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    competition='lg',\n",
    "    _wandb_kernel='deb'\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET SEED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "\n",
    "set_seed(CONFIG['seed'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = ''\n",
    "TEST_PATH = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05,\n",
    "                           rotate_limit=15, p=0.5),\n",
    "        A.RGBShift(r_shift_limit=15, g_shift_limit=15,\n",
    "                   b_shift_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()], p=1.),\n",
    "\n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()], p=1.)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, backbone, embedder, pretrained=True):\n",
    "        super(Model, self).__init__()\n",
    "        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n",
    "        self.n_features = self.backbone.head.in_features\n",
    "        self.backbone.reset_classifier(0)\n",
    "        self.fc = nn.Linear(self.n_features, CONFIG['num_classes'])\n",
    "\n",
    "    def forward(self, images):\n",
    "        # features = (bs, embedding_size)\n",
    "        features = self.backbone(images)\n",
    "        # outputs  = (bs, num_classes)\n",
    "        output = self.fc(features)\n",
    "        return output\n",
    "\n",
    "\n",
    "model = Model(CONFIG['backbone'], CONFIG['embedder'], pretrained = False)\n",
    "model.to(CONFIG['device'])\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9aea7b6a7444b8f7906e49a0ee5a1a1954c47b5d0459b9029b34272caa5266f3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
